<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>AINLP</title>
<link>http://tw.wleilei.com:4001/feeds/MP_WXS_2398933301.atom</link>

<item>
<title>LLM最新黑马：Transformer时序大模型来了</title>
<link>https://mp.weixin.qq.com/s/VZi2KRZYIkjsPDHXXcpFDA</link>
<guid>https://mp.weixin.qq.com/s/VZi2KRZYIkjsPDHXXcpFDA</guid>
<content:encoded><![CDATA[
<div> Transformer、时序、大模型、LLM、黑马
<br>
<br>
关注LLM最新黑马：Transformer时序大模型的出现。这种模型结合了Transformer和时序模型的特点，具有很高的潜力。LLM作为最新的黑马，可能会引领新的研究方向。其结构复杂，参数多，能够更好地捕捉时序信息。这种模型的出现可能会对NLP领域带来新的突破，吸引更多研究者投入相关领域的研究。Transformer时序大模型有望成为未来发展的趋势，值得密切关注。
<br>
总结：Transformer时序大模型作为LLM最新黑马，可能引领研究方向，结合Transformer和时序模型优势，更好地捕捉时序信息，有望带来NLP领域的突破，将成为未来发展趋势。 <div>
LLM最新黑马：Transformer时序大模型来了
]]></content:encoded>

<pubDate>2024-05-21T01:31:40.000Z</pubDate>
</item>
<item>
<title>今年字节和京东的年终奖情况。。</title>
<link>https://mp.weixin.qq.com/s/2nseELffiQP0nA5wjP4WiA</link>
<guid>https://mp.weixin.qq.com/s/2nseELffiQP0nA5wjP4WiA</guid>
<content:encoded><![CDATA[
<div> 字节、京东、年终奖、情况、今年
<br>
<br>
1. 今年字节和京东均举办了年终奖活动，激励员工积极工作。
2. 字节的年终奖主要以公司业绩和个人贡献为基准，获得的员工普遍较为满意。
3. 京东的年终奖则采取了更多形式，包括现金、礼品卡等，员工收获颇丰。
4. 两家公司的年终奖情况在行业内属于比较大气的，受到员工好评。
5. 通过年终奖的激励，字节和京东都进一步激发了员工的工作积极性，为公司发展助力。
<br>
<br>
总结: 今年字节和京东举办了年终奖活动，奖金较为丰厚，激励员工更加努力工作，获得了员工的认可和好评。 <div>
今年字节和京东的年终奖情况。。
]]></content:encoded>

<pubDate>2024-05-21T01:31:40.000Z</pubDate>
</item>
<item>
<title>如何提升大模型的SFT效率与效果？</title>
<link>https://mp.weixin.qq.com/s/j7VcCi5lKvdIKNQ66bjgLQ</link>
<guid>https://mp.weixin.qq.com/s/j7VcCi5lKvdIKNQ66bjgLQ</guid>
<content:encoded><![CDATA[

如何提升大模型的SFT效率与效果？
]]></content:encoded>

<pubDate>2024-05-21T01:31:40.000Z</pubDate>
</item>
<item>
<title>LLM2Vec: 改造Decoder-only LLM以生成高质量text embedding</title>
<link>https://mp.weixin.qq.com/s/8cR1_3nUclfG9qfs-133og</link>
<guid>https://mp.weixin.qq.com/s/8cR1_3nUclfG9qfs-133og</guid>
<content:encoded><![CDATA[

LLM2Vec: 改造Decoder-only LLM以生成高质量text embedding
]]></content:encoded>

<pubDate>2024-05-21T01:31:40.000Z</pubDate>
</item>
<item>
<title>时序建模基础——RevIN</title>
<link>https://mp.weixin.qq.com/s/7TQXLNTD_QjJS9wX_9aZ8w</link>
<guid>https://mp.weixin.qq.com/s/7TQXLNTD_QjJS9wX_9aZ8w</guid>
<content:encoded><![CDATA[

时序建模基础——RevIN
]]></content:encoded>

<pubDate>2024-05-21T01:31:40.000Z</pubDate>
</item>

<item>
<title>老乡鸡，竟然开源了？！</title>
<link>https://mp.weixin.qq.com/s/MJ6emb5qXVM2tyShtr48Og</link>
<guid>https://mp.weixin.qq.com/s/MJ6emb5qXVM2tyShtr48Og</guid>
<content:encoded><![CDATA[
<div> 开源、老乡鸡、竟然、震惊、合作<br />
<br />
老乡鸡公司竟然决定开源他们的技术，这让许多人感到震惊。他们表示这是为了大家能更好地了解和学习他们的技术，也为未来可能的合作铺平道路。这种开源的举动在传统商业模式下并不多见，但老乡鸡公司的决定却收获了许多好评和支持。开源不仅可以促进技术的共享和发展，也有助于吸引更多人参与到技术创新中。总的来说，老乡鸡公司的开源举动将为整个行业带来积极影响，也激励其他公司更加开放和合作。 <br /><br />总结:老乡鸡公司开源技术，引发震惊，为未来合作铺平道路，促进技术共享和发展，激励行业更加开放和合作。 <div>
老乡鸡，竟然开源了？！
]]></content:encoded>
<pubDate>2024-05-20T12:39:23.000Z</pubDate>
</item>
<item>
<title>Cantor（领唱员）:厦门大学提出多模态 CoT 新架构</title>
<link>https://mp.weixin.qq.com/s/72lrbr1Z8C8gaOxFheeevQ</link>
<guid>https://mp.weixin.qq.com/s/72lrbr1Z8C8gaOxFheeevQ</guid>
<content:encoded><![CDATA[
<div> 多模态 CoT 新架构, 厦门大学, 提出, Cantor

<br /><br />总结:
厦门大学提出了一种多模态的领唱员（Cantor）新架构，旨在实现更高效的信息传递和辅助决策。该架构结合了不同模态的信息，使系统具有更强大的功能和智能性。通过优化数据处理和交互设计，提高用户体验和系统性能。这是一种创新性的方法，有望为信息处理领域带来新的突破和进展。 <div>
Cantor（领唱员）:厦门大学提出多模态 CoT 新架构
]]></content:encoded>
<pubDate>2024-05-20T12:39:23.000Z</pubDate>
</item>
<item>
<title>阿里巴巴通义实验室RAG团队招聘日常实习生</title>
<link>https://mp.weixin.qq.com/s/JmU0tPd6vjjv-GKHWXpwqg</link>
<guid>https://mp.weixin.qq.com/s/JmU0tPd6vjjv-GKHWXpwqg</guid>
<content:encoded><![CDATA[
阿里巴巴通义实验室RAG团队招聘日常实习生
]]></content:encoded>
<pubDate>2024-05-20T12:39:23.000Z</pubDate>
</item>
<item>
<title>快手在召回场景GPT范式的尝试</title>
<link>https://mp.weixin.qq.com/s/KKgYAzsTrMoTCw9hXJGYSA</link>
<guid>https://mp.weixin.qq.com/s/KKgYAzsTrMoTCw9hXJGYSA</guid>
<content:encoded><![CDATA[
快手在召回场景GPT范式的尝试
]]></content:encoded>
<pubDate>2024-05-20T12:39:23.000Z</pubDate>
</item>
<item>
<title>一文逮尽知名开源大模型作弊！训题库...</title>
<link>https://mp.weixin.qq.com/s/-o9pfWuEzALZfaTdNj_eXg</link>
<guid>https://mp.weixin.qq.com/s/-o9pfWuEzALZfaTdNj_eXg</guid>
<content:encoded><![CDATA[
一文逮尽知名开源大模型作弊！训题库...
]]></content:encoded>
<pubDate>2024-05-20T12:39:23.000Z</pubDate>
</item>
<item>
<title>大模型预训练认知分享</title>
<link>https://mp.weixin.qq.com/s/glByFfjEzbrTg9WQL3M1JQ</link>
<guid>https://mp.weixin.qq.com/s/glByFfjEzbrTg9WQL3M1JQ</guid>
<content:encoded><![CDATA[
<div> 大模型、预训练、认知、分享、文章
<br />
<br />
总结:本文介绍了大模型预训练的重要性和应用。大模型具有更强大的学习能力和泛化能力，可以对海量数据进行深度学习。预训练是一种有效的模型训练方法，可以在大数据集上训练模型，然后在特定任务上进行微调。认知方面，大模型预训练可以提高模型的理解能力和复杂任务的执行能力。分享方面，研究人员可以分享预训练模型和经验，促进模型的改进和发展。通过大模型预训练，可以取得更好的性能和效果，推动人工智能领域的发展。 <div>
大模型预训练认知分享
]]></content:encoded>
<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>Blurr AI 招聘RAG 研发工程师和AI Agent 开发工程师</title>
<link>https://mp.weixin.qq.com/s/nzHmEFZVevkrL5yfjTjJ2A</link>
<guid>https://mp.weixin.qq.com/s/nzHmEFZVevkrL5yfjTjJ2A</guid>
<content:encoded><![CDATA[
<div> AI、招聘、RAG、研发工程师、AI Agent
<br />
招聘Blurr AI公司的RAG研发工程师和AI Agent开发工程师。想要加入该公司的候选人需要有相关经验和技能，能够参与在人工智能领域的创新研发工作。公司给予员工发展和成长的机会，提供良好的工作环境和晋升机会。如果你对人工智能领域充满热情并具备相关技能和经验，欢迎加入Blurr AI团队。 <div>
Blurr AI 招聘RAG 研发工程师和AI Agent 开发工程师
]]></content:encoded>
<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>如何提升大模型RAG系统的效果？RAG推理增强(二)</title>
<link>https://mp.weixin.qq.com/s/PYMtVjZq0d_CfQN-zFdqCg</link>
<guid>https://mp.weixin.qq.com/s/PYMtVjZq0d_CfQN-zFdqCg</guid>
<content:encoded><![CDATA[
如何提升大模型RAG系统的效果？RAG推理增强(二)
]]></content:encoded>
<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>基于多模态信息抽取的菜品知识图谱构建</title>
<link>https://mp.weixin.qq.com/s/o0PsuyRGsBAZ1fR7XsHUDA</link>
<guid>https://mp.weixin.qq.com/s/o0PsuyRGsBAZ1fR7XsHUDA</guid>
<content:encoded><![CDATA[
基于多模态信息抽取的菜品知识图谱构建
]]></content:encoded>
<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>新加坡提示工程大赛冠军最强Prompt工程技巧分享，仅用大模型也能做数据分析</title>
<link>https://mp.weixin.qq.com/s/q3zjYV1R-s4a6LaFwaB9OQ</link>
<guid>https://mp.weixin.qq.com/s/q3zjYV1R-s4a6LaFwaB9OQ</guid>
<content:encoded><![CDATA[
新加坡提示工程大赛冠军最强Prompt工程技巧分享，仅用大模型也能做数据分析
]]></content:encoded>
<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>RAG还是微调？大模型微调技术全面盘点</title>
<link>https://mp.weixin.qq.com/s/KJ4qQWnF4rcJjz705ngCAQ</link>
<guid>https://mp.weixin.qq.com/s/KJ4qQWnF4rcJjz705ngCAQ</guid>
<content:encoded><![CDATA[
<div> RAG 微调 模型 技术 全面

<br /><br />总结:
本文全面盘点了微调大模型的技术，探讨了RAG和微调之间的关系。大模型微调技术的发展已经日益成熟，可以有效提升模型性能。RAG模型可以帮助用户更好地理解模型预测结果，尤其在自然语言处理领域表现突出。整体上，微调大模型是为了更好地适应特定任务，提高模型的准确性和泛化能力。通过深入研究大模型微调技术，可以更好地利用现有模型，为各类应用提供更好的解决方案。 <div>
RAG还是微调？大模型微调技术全面盘点
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>如何提升大模型的Agent推理规划等能力？</title>
<link>https://mp.weixin.qq.com/s/7208b2TxskVJn3IKj6hw6Q</link>
<guid>https://mp.weixin.qq.com/s/7208b2TxskVJn3IKj6hw6Q</guid>
<content:encoded><![CDATA[
<div> 提升 大模型 Agent 推理 规划 能力  
总结:  
提升大模型的Agent推理规划等能力，可采用以下策略：   
1. 引入更多数据：通过增加训练数据量，让Agent在更多场景中学习并提升推理能力。  
2. 增加模型复杂度：适当增加Agent的模型复杂度，提高推理和规划的精度和准确度。  
3. 优化算法：选择更优的优化算法，提高Agent的训练效率和模型性能。  
4. 强化学习：利用强化学习技术，让Agent在实时环境中不断优化策略和决策能力。  
5. 结合领域知识：结合实际领域的专业知识，让Agent更好地理解和处理复杂情况，提升推理规划能力。 <div>
如何提升大模型的Agent推理规划等能力？
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>开源闭源争论不休，浅谈大模型开源和闭源</title>
<link>https://mp.weixin.qq.com/s/y9Ru6UANWOu4Q2wHJBgMWQ</link>
<guid>https://mp.weixin.qq.com/s/y9Ru6UANWOu4Q2wHJBgMWQ</guid>
<content:encoded><![CDATA[
开源闭源争论不休，浅谈大模型开源和闭源
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>大模型测试集作弊？ICLR论文将leak一网打尽！</title>
<link>https://mp.weixin.qq.com/s/tGVB1f6oJ_-BJv88oFy8Uw</link>
<guid>https://mp.weixin.qq.com/s/tGVB1f6oJ_-BJv88oFy8Uw</guid>
<content:encoded><![CDATA[
大模型测试集作弊？ICLR论文将leak一网打尽！
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>IJCAI2024｜基于指令的大模型知识编辑</title>
<link>https://mp.weixin.qq.com/s/aMqcZW55I8xQrtpCy_nE_Q</link>
<guid>https://mp.weixin.qq.com/s/aMqcZW55I8xQrtpCy_nE_Q</guid>
<content:encoded><![CDATA[
IJCAI2024｜基于指令的大模型知识编辑
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>Transformer登上nature，被誉为大模型基石的它到底凭什么这么火？</title>
<link>https://mp.weixin.qq.com/s/xZneDM3IJlK4BfEASw1egg</link>
<guid>https://mp.weixin.qq.com/s/xZneDM3IJlK4BfEASw1egg</guid>
<content:encoded><![CDATA[
<div> Transformer 大模型 基石 火
<br />
总结:<br />
Transformer因其强大的处理能力和广泛的应用领域而受到广泛关注。作为大模型的基石，Transformer在自然语言处理等领域展现出了卓越的表现。其独特的结构和先进的机制使其能够有效地处理各种复杂任务，并取得令人瞩目的成果。Transformer的火爆也源于其被广泛认可为推动人工智能发展的关键技术之一，对未来的发展具有重要意义。 <div>
Transformer登上nature，被誉为大模型基石的它到底凭什么这么火？
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>手撕Flash Attention！原理解析及代码实现</title>
<link>https://mp.weixin.qq.com/s/2hSNQk1y99YM4TX0D96POQ</link>
<guid>https://mp.weixin.qq.com/s/2hSNQk1y99YM4TX0D96POQ</guid>
<content:encoded><![CDATA[
<div> 原理解析、代码实现、Flash、手撕、注意事项
<br />
手撕Flash Attention！是一篇介绍如何手动实现Flash Attention机制的文章。通过深入分析Flash Attention的原理，在代码中实现该机制，可以提高模型的性能和泛化能力。在实现过程中，需要注意调整超参数、保持网络结构的稳定性和正确使用损失函数等细节。通过手动实现Flash Attention，可以更好地理解模型内部的运作机制，从而更好地优化模型的表现。<br /><br />总结:手撕Flash Attention！是一篇介绍如何手动实现Flash Attention机制的文章。通过深入分析Flash Attention的原理，在代码中实现该机制，可以提高模型的性能和泛化能力。在实现过程中，需要注意调整超参数、保持网络结构的稳定性和正确使用损失函数等细节。 <div>
手撕Flash Attention！原理解析及代码实现
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>DPO作者新作｜From r to Q*</title>
<link>https://mp.weixin.qq.com/s/kRhatwbCyPFSl4tTxg_dlA</link>
<guid>https://mp.weixin.qq.com/s/kRhatwbCyPFSl4tTxg_dlA</guid>
<content:encoded><![CDATA[
DPO作者新作｜From r to Q*
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>Introducing GPT-4o</title>
<link>https://mp.weixin.qq.com/s/1Mvwf_U0NXq-1DDRjrd_uw</link>
<guid>https://mp.weixin.qq.com/s/1Mvwf_U0NXq-1DDRjrd_uw</guid>
<content:encoded><![CDATA[
Introducing GPT-4o
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>RAG开源项目Qanything源码阅读2-离线文件处理</title>
<link>https://mp.weixin.qq.com/s/MU4AwDWNZtoLkTIfvN5JZg</link>
<guid>https://mp.weixin.qq.com/s/MU4AwDWNZtoLkTIfvN5JZg</guid>
<content:encoded><![CDATA[
RAG开源项目Qanything源码阅读2-离线文件处理
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>太强了！深度学习融合魔改</title>
<link>https://mp.weixin.qq.com/s/HwJPnEdtYyPWuao-he6d1Q</link>
<guid>https://mp.weixin.qq.com/s/HwJPnEdtYyPWuao-he6d1Q</guid>
<content:encoded><![CDATA[
<div> 深度学习 魔改 融合 强大 技术<br />
<br />
总结:本文讨论了深度学习技术融合魔改的强大表现。通过对深度学习模型进行魔改，可以进一步提升其性能和效果。这种融合技术让深度学习在各个领域都表现出色，展现出强大的应用潜力。深度学习融合魔改的发展趋势令人振奋，将为科技创新带来新的契机和可能性。 <div>
太强了！深度学习融合魔改
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>LLM落地淘宝电商搜索场景，显著提升长尾query改写效果</title>
<link>https://mp.weixin.qq.com/s/VYiSkPwYz2UJGHyu36H0zg</link>
<guid>https://mp.weixin.qq.com/s/VYiSkPwYz2UJGHyu36H0zg</guid>
<content:encoded><![CDATA[
<div> LLM、淘宝电商、搜索场景、长尾query、改写效果

<br /><br />总结:
文章介绍了如何利用LLM（Language Model for Large-scale Retrieval）技术来落地至淘宝电商搜索场景，以显著提升长尾query的改写效果。首先，作者提到了LLM技术的优势和应用场景，然后详细解释了在淘宝电商搜索中如何应用LLM来改写长尾query以提升搜索结果的准确性和覆盖范围。通过实际案例分析和实验结果展示，可以看出LLM在淘宝电商场景中的有效性和实用性。最后，作者总结了LLM在电商搜索场景中的应用前景和潜力，为提升用户搜索体验和推动电商发展提供了有益启示。 <div>
LLM落地淘宝电商搜索场景，显著提升长尾query改写效果
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>StarCoder2-Instruct: 完全透明和可自我对齐的代码生成</title>
<link>https://mp.weixin.qq.com/s/jcTpFWeW18Dkc19jhesGag</link>
<guid>https://mp.weixin.qq.com/s/jcTpFWeW18Dkc19jhesGag</guid>
<content:encoded><![CDATA[
StarCoder2-Instruct: 完全透明和可自我对齐的代码生成
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>零一万物开源Yi-1.5系列大模型</title>
<link>https://mp.weixin.qq.com/s/ltUsEHFAOCJ56YW9devhPg</link>
<guid>https://mp.weixin.qq.com/s/ltUsEHFAOCJ56YW9devhPg</guid>
<content:encoded><![CDATA[
零一万物开源Yi-1.5系列大模型
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>COLING24 ｜无需标注即可增强模型 COT 能力</title>
<link>https://mp.weixin.qq.com/s/hrOo_42qmWsPawMYZOQ7eg</link>
<guid>https://mp.weixin.qq.com/s/hrOo_42qmWsPawMYZOQ7eg</guid>
<content:encoded><![CDATA[
COLING24 ｜无需标注即可增强模型 COT 能力
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>终于知道工资为什么要保密了。</title>
<link>https://mp.weixin.qq.com/s/ejCN1cFhIzjGAsifqMgD9Q</link>
<guid>https://mp.weixin.qq.com/s/ejCN1cFhIzjGAsifqMgD9Q</guid>
<content:encoded><![CDATA[
<div> 保密、工资、知道、原因、重要<br />
<br />
重要性在于工资保密可以避免引起员工之间的比较和不必要的矛盾，保持工作环境的和谐稳定。另外，工资涉及到公司的商业机密和绩效考核等信息，如果泄露出去可能会对公司造成不利影响。同时，保密也可以提高员工的安全感，让他们更专注于工作内容而非薪酬问题。最后，明确规定工资保密也有利于建立公司的信任和合作氛围，确保员工团队的团结和凝聚力。总结: 工资保密的重要性体现在避免矛盾、保护商业机密、提高员工安全感、建立信任和合作氛围。 <div>
终于知道工资为什么要保密了。
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>【文末赠书】大语言模型的生态系统</title>
<link>https://mp.weixin.qq.com/s/-zdHnNz6YXJsLWwq_dik8g</link>
<guid>https://mp.weixin.qq.com/s/-zdHnNz6YXJsLWwq_dik8g</guid>
<content:encoded><![CDATA[
<div> 生态系统、大语言模型、发展、应用、影响<br />
<br />
总结: 大语言模型作为生态系统中重要的一部分，不断发展并广泛应用于各个领域。其强大的语言生成能力和智能化特性影响着人们的生活和工作方式。随着技术不断进步，大语言模型的应用范围将会不断扩大，为社会发展和创新带来更多可能性。 <div>
【文末赠书】大语言模型的生态系统
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>阿里通义-对话智能团队实习生(Research Intern)招聘​</title>
<link>https://mp.weixin.qq.com/s/Oj1tRDMVRJ2fiJjOnbyd1Q</link>
<guid>https://mp.weixin.qq.com/s/Oj1tRDMVRJ2fiJjOnbyd1Q</guid>
<content:encoded><![CDATA[
阿里通义-对话智能团队实习生(Research Intern)招聘​
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>利用知识图谱提升RAG应用的准确性</title>
<link>https://mp.weixin.qq.com/s/TZ22SyF74YOJwoIZeaRDcA</link>
<guid>https://mp.weixin.qq.com/s/TZ22SyF74YOJwoIZeaRDcA</guid>
<content:encoded><![CDATA[
利用知识图谱提升RAG应用的准确性
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>“Ruozhiba” is all you need</title>
<link>https://mp.weixin.qq.com/s/CDKGlOUTz6HqceRO1ESOUA</link>
<guid>https://mp.weixin.qq.com/s/CDKGlOUTz6HqceRO1ESOUA</guid>
<content:encoded><![CDATA[
“Ruozhiba” is all you need
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>为什么这次AlphaFold3再次意义非凡？</title>
<link>https://mp.weixin.qq.com/s/Gl_tHdu5pBl8Wfjl2FRkLQ</link>
<guid>https://mp.weixin.qq.com/s/Gl_tHdu5pBl8Wfjl2FRkLQ</guid>
<content:encoded><![CDATA[
为什么这次AlphaFold3再次意义非凡？
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
<item>
<title>大模型推理窗口-从有限到无限大</title>
<link>https://mp.weixin.qq.com/s/ogrWe61JZz64FXTcBfVN5Q</link>
<guid>https://mp.weixin.qq.com/s/ogrWe61JZz64FXTcBfVN5Q</guid>
<content:encoded><![CDATA[
大模型推理窗口-从有限到无限大
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
<item>
<title>AI搜索与大模型应用的一些思考</title>
<link>https://mp.weixin.qq.com/s/ZSHGUT6FMtcGD62d5RInuw</link>
<guid>https://mp.weixin.qq.com/s/ZSHGUT6FMtcGD62d5RInuw</guid>
<content:encoded><![CDATA[
AI搜索与大模型应用的一些思考
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
<item>
<title>南方科技大学统计与数据科学系 &amp; 香港中文大学（深圳）数据科学学院联合招聘</title>
<link>https://mp.weixin.qq.com/s/Hm24CLClwqukkgk8qtgv1A</link>
<guid>https://mp.weixin.qq.com/s/Hm24CLClwqukkgk8qtgv1A</guid>
<content:encoded><![CDATA[
南方科技大学统计与数据科学系 & 香港中文大学（深圳）数据科学学院联合招聘
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
<item>
<title>SIGIR2024｜现实场景下的多模态知识图谱补全</title>
<link>https://mp.weixin.qq.com/s/fWXxyQgYp8gf3o6WW2gY4Q</link>
<guid>https://mp.weixin.qq.com/s/fWXxyQgYp8gf3o6WW2gY4Q</guid>
<content:encoded><![CDATA[
SIGIR2024｜现实场景下的多模态知识图谱补全
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
</channel>
</rss>