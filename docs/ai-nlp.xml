<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>AINLP</title>
<link>http://tw.wleilei.com:4001/feeds/MP_WXS_2398933301.atom</link>

<item>
<title>最后十天！参加一场AI竞赛，血赚31万！</title>
<link>https://mp.weixin.qq.com/s/ljdQy38Fg2zGWq_pq4b8fA</link>
<guid>https://mp.weixin.qq.com/s/ljdQy38Fg2zGWq_pq4b8fA</guid>
<content:encoded><![CDATA[
<div> 竞赛, AI, 血赚, 31万, 最后十天
<br>
AI竞赛最后十天参加，成功血赚31万。 <div>
最后十天！参加一场AI竞赛，血赚31万！
]]></content:encoded>

<pubDate>2024-05-22T14:32:55.000Z</pubDate>
</item>
<item>
<title>LLM“最难刷分模型测评”出炉，国产黑马与GPT-4o同列金字塔尖</title>
<link>https://mp.weixin.qq.com/s/F85igxpthoCx0Ey7f2parA</link>
<guid>https://mp.weixin.qq.com/s/F85igxpthoCx0Ey7f2parA</guid>
<content:encoded><![CDATA[
<div> 最难刷分模型测评 国产黑马 GPT-4o 金字塔尖

总结：<br>
1. 最难刷分模型测评结果出炉，国产黑马与GPT-4o同列金字塔尖。
2. 测评结果显示这两个模型在性能上有着非凡表现，领先于其他竞争对手。
3. 国产黑马和GPT-4o的实力和表现让人们刮目相看，展现出了国内人工智能领域的强大实力。
4. 这次测评为人工智能技术发展提供了有力的参考和指导，有望推动行业技术进步。
5. 未来国产黑马和GPT-4o有望继续在人工智能领域中发挥重要作用，引领行业发展。 <br> <div>
LLM“最难刷分模型测评”出炉，国产黑马与GPT-4o同列金字塔尖
]]></content:encoded>

<pubDate>2024-05-22T14:32:55.000Z</pubDate>
</item>
<item>
<title>重新思考视觉语言模型中被忽视的方面</title>
<link>https://mp.weixin.qq.com/s/WXNxKejGEcFkMujRoogM5Q</link>
<guid>https://mp.weixin.qq.com/s/WXNxKejGEcFkMujRoogM5Q</guid>
<content:encoded><![CDATA[

重新思考视觉语言模型中被忽视的方面
]]></content:encoded>

<pubDate>2024-05-22T14:32:55.000Z</pubDate>
</item>
<item>
<title>现有开源MOE大模型对比</title>
<link>https://mp.weixin.qq.com/s/EvUpCM_ZqPfUiMz_XrChZg</link>
<guid>https://mp.weixin.qq.com/s/EvUpCM_ZqPfUiMz_XrChZg</guid>
<content:encoded><![CDATA[

现有开源MOE大模型对比
]]></content:encoded>

<pubDate>2024-05-22T14:32:55.000Z</pubDate>
</item>
<item>
<title>ResearchAgent: 利用agent自动生成论文idea，再也不用担心做科研没有思路了</title>
<link>https://mp.weixin.qq.com/s/YCeQiA3Ahx7qBo8LH38thQ</link>
<guid>https://mp.weixin.qq.com/s/YCeQiA3Ahx7qBo8LH38thQ</guid>
<content:encoded><![CDATA[

ResearchAgent: 利用agent自动生成论文idea，再也不用担心做科研没有思路了
]]></content:encoded>

<pubDate>2024-05-22T14:32:55.000Z</pubDate>
</item>

<item>
<title>GPT-4o再次封神！全网独一份的AI大模型教程</title>
<link>https://mp.weixin.qq.com/s/uCrGz1u9v1ek2SY-gA0vDA</link>
<guid>https://mp.weixin.qq.com/s/uCrGz1u9v1ek2SY-gA0vDA</guid>
<content:encoded><![CDATA[
<div> 模型、教程、AI、GPT-4、封神
总结:<br /><br />本文介绍了全网独一份的AI大模型教程，重点关注了GPT-4模型的应用和特点。文章从介绍模型基本原理和结构开始，详细解释了如何使用AI大模型进行各种任务，包括自然语言处理、图像识别等。同时，还介绍了如何优化模型性能和训练技巧，帮助读者更好地理解和应用AI技术。总的来说，这篇文章为读者提供了一份全面且深入的AI大模型教程，帮助他们更好地了解和利用最新的人工智能技术。 <div>
GPT-4o再次封神！全网独一份的AI大模型教程
]]></content:encoded>
<pubDate>2024-05-22T01:37:26.000Z</pubDate>
</item>
<item>
<title>突破性AGI综述：UIUC 120页长文揭示离AGI仅一步之遥？</title>
<link>https://mp.weixin.qq.com/s/WBqj4kYNWzrTfxVKkFISog</link>
<guid>https://mp.weixin.qq.com/s/WBqj4kYNWzrTfxVKkFISog</guid>
<content:encoded><![CDATA[
<div> AGI、UIUC、120页、突破性、综述
<br />
AGI是人工智能领域的终极目标，UIUC研究团队发表了一篇120页长文综述，揭示离AGI可能仅一步之遥。文中提到了AGI的突破性进展，以及UIUC团队对实现AGI的研究和思路。该综述引起了广泛关注，许多研究者认为AGI的实现只是时间问题。总结:UIUC团队发表的120页综述揭示了AGI实现的突破性进展，令人相信AGI可能离我们只有一步之遥。 <div>
突破性AGI综述：UIUC 120页长文揭示离AGI仅一步之遥？
]]></content:encoded>
<pubDate>2024-05-22T01:37:26.000Z</pubDate>
</item>
<item>
<title>浅谈大模型 SFT 的实践落地：10 问 10 答</title>
<link>https://mp.weixin.qq.com/s/ftuTTIqUymF5xB6LwQi-kw</link>
<guid>https://mp.weixin.qq.com/s/ftuTTIqUymF5xB6LwQi-kw</guid>
<content:encoded><![CDATA[
浅谈大模型 SFT 的实践落地：10 问 10 答
]]></content:encoded>
<pubDate>2024-05-22T01:37:26.000Z</pubDate>
</item>
<item>
<title>【LLM &amp; 长文本】Infini-attention：高效无限上下文 Transformer</title>
<link>https://mp.weixin.qq.com/s/UDE-bRENp8z5OdH-sC0nRg</link>
<guid>https://mp.weixin.qq.com/s/UDE-bRENp8z5OdH-sC0nRg</guid>
<content:encoded><![CDATA[
【LLM & 长文本】Infini-attention：高效无限上下文 Transformer
]]></content:encoded>
<pubDate>2024-05-22T01:37:26.000Z</pubDate>
</item>
<item>
<title>OpenAI前CTO Ilya推荐的30篇文章，认真读完将理解当下90%的AI技术（1-10）</title>
<link>https://mp.weixin.qq.com/s/3HX8DBVMZTNw6zEg4XJ3lg</link>
<guid>https://mp.weixin.qq.com/s/3HX8DBVMZTNw6zEg4XJ3lg</guid>
<content:encoded><![CDATA[
OpenAI前CTO Ilya推荐的30篇文章，认真读完将理解当下90%的AI技术（1-10）
]]></content:encoded>
<pubDate>2024-05-22T01:37:26.000Z</pubDate>
</item>
<item>
<title>LLM最新黑马：Transformer时序大模型来了</title>
<link>https://mp.weixin.qq.com/s/VZi2KRZYIkjsPDHXXcpFDA</link>
<guid>https://mp.weixin.qq.com/s/VZi2KRZYIkjsPDHXXcpFDA</guid>
<content:encoded><![CDATA[
<div> Transformer、时序、大模型、LLM、黑马
<br />
<br />
关注LLM最新黑马：Transformer时序大模型的出现。这种模型结合了Transformer和时序模型的特点，具有很高的潜力。LLM作为最新的黑马，可能会引领新的研究方向。其结构复杂，参数多，能够更好地捕捉时序信息。这种模型的出现可能会对NLP领域带来新的突破，吸引更多研究者投入相关领域的研究。Transformer时序大模型有望成为未来发展的趋势，值得密切关注。
<br />
总结：Transformer时序大模型作为LLM最新黑马，可能引领研究方向，结合Transformer和时序模型优势，更好地捕捉时序信息，有望带来NLP领域的突破，将成为未来发展趋势。 <div>
LLM最新黑马：Transformer时序大模型来了
]]></content:encoded>
<pubDate>2024-05-21T01:31:40.000Z</pubDate>
</item>
<item>
<title>今年字节和京东的年终奖情况。。</title>
<link>https://mp.weixin.qq.com/s/2nseELffiQP0nA5wjP4WiA</link>
<guid>https://mp.weixin.qq.com/s/2nseELffiQP0nA5wjP4WiA</guid>
<content:encoded><![CDATA[
<div> 字节、京东、年终奖、情况、今年
<br />
<br />
1. 今年字节和京东均举办了年终奖活动，激励员工积极工作。
2. 字节的年终奖主要以公司业绩和个人贡献为基准，获得的员工普遍较为满意。
3. 京东的年终奖则采取了更多形式，包括现金、礼品卡等，员工收获颇丰。
4. 两家公司的年终奖情况在行业内属于比较大气的，受到员工好评。
5. 通过年终奖的激励，字节和京东都进一步激发了员工的工作积极性，为公司发展助力。
<br />
<br />
总结: 今年字节和京东举办了年终奖活动，奖金较为丰厚，激励员工更加努力工作，获得了员工的认可和好评。 <div>
今年字节和京东的年终奖情况。。
]]></content:encoded>
<pubDate>2024-05-21T01:31:40.000Z</pubDate>
</item>
<item>
<title>如何提升大模型的SFT效率与效果？</title>
<link>https://mp.weixin.qq.com/s/j7VcCi5lKvdIKNQ66bjgLQ</link>
<guid>https://mp.weixin.qq.com/s/j7VcCi5lKvdIKNQ66bjgLQ</guid>
<content:encoded><![CDATA[
如何提升大模型的SFT效率与效果？
]]></content:encoded>
<pubDate>2024-05-21T01:31:40.000Z</pubDate>
</item>
<item>
<title>LLM2Vec: 改造Decoder-only LLM以生成高质量text embedding</title>
<link>https://mp.weixin.qq.com/s/8cR1_3nUclfG9qfs-133og</link>
<guid>https://mp.weixin.qq.com/s/8cR1_3nUclfG9qfs-133og</guid>
<content:encoded><![CDATA[
LLM2Vec: 改造Decoder-only LLM以生成高质量text embedding
]]></content:encoded>
<pubDate>2024-05-21T01:31:40.000Z</pubDate>
</item>
<item>
<title>时序建模基础——RevIN</title>
<link>https://mp.weixin.qq.com/s/7TQXLNTD_QjJS9wX_9aZ8w</link>
<guid>https://mp.weixin.qq.com/s/7TQXLNTD_QjJS9wX_9aZ8w</guid>
<content:encoded><![CDATA[
时序建模基础——RevIN
]]></content:encoded>
<pubDate>2024-05-21T01:31:40.000Z</pubDate>
</item>
<item>
<title>老乡鸡，竟然开源了？！</title>
<link>https://mp.weixin.qq.com/s/MJ6emb5qXVM2tyShtr48Og</link>
<guid>https://mp.weixin.qq.com/s/MJ6emb5qXVM2tyShtr48Og</guid>
<content:encoded><![CDATA[
<div> 开源、老乡鸡、竟然、震惊、合作<br />
<br />
老乡鸡公司竟然决定开源他们的技术，这让许多人感到震惊。他们表示这是为了大家能更好地了解和学习他们的技术，也为未来可能的合作铺平道路。这种开源的举动在传统商业模式下并不多见，但老乡鸡公司的决定却收获了许多好评和支持。开源不仅可以促进技术的共享和发展，也有助于吸引更多人参与到技术创新中。总的来说，老乡鸡公司的开源举动将为整个行业带来积极影响，也激励其他公司更加开放和合作。 <br /><br />总结:老乡鸡公司开源技术，引发震惊，为未来合作铺平道路，促进技术共享和发展，激励行业更加开放和合作。 <div>
老乡鸡，竟然开源了？！
]]></content:encoded>
<pubDate>2024-05-20T12:39:23.000Z</pubDate>
</item>
<item>
<title>Cantor（领唱员）:厦门大学提出多模态 CoT 新架构</title>
<link>https://mp.weixin.qq.com/s/72lrbr1Z8C8gaOxFheeevQ</link>
<guid>https://mp.weixin.qq.com/s/72lrbr1Z8C8gaOxFheeevQ</guid>
<content:encoded><![CDATA[
<div> 多模态 CoT 新架构, 厦门大学, 提出, Cantor

<br /><br />总结:
厦门大学提出了一种多模态的领唱员（Cantor）新架构，旨在实现更高效的信息传递和辅助决策。该架构结合了不同模态的信息，使系统具有更强大的功能和智能性。通过优化数据处理和交互设计，提高用户体验和系统性能。这是一种创新性的方法，有望为信息处理领域带来新的突破和进展。 <div>
Cantor（领唱员）:厦门大学提出多模态 CoT 新架构
]]></content:encoded>
<pubDate>2024-05-20T12:39:23.000Z</pubDate>
</item>
<item>
<title>阿里巴巴通义实验室RAG团队招聘日常实习生</title>
<link>https://mp.weixin.qq.com/s/JmU0tPd6vjjv-GKHWXpwqg</link>
<guid>https://mp.weixin.qq.com/s/JmU0tPd6vjjv-GKHWXpwqg</guid>
<content:encoded><![CDATA[
阿里巴巴通义实验室RAG团队招聘日常实习生
]]></content:encoded>
<pubDate>2024-05-20T12:39:23.000Z</pubDate>
</item>
<item>
<title>快手在召回场景GPT范式的尝试</title>
<link>https://mp.weixin.qq.com/s/KKgYAzsTrMoTCw9hXJGYSA</link>
<guid>https://mp.weixin.qq.com/s/KKgYAzsTrMoTCw9hXJGYSA</guid>
<content:encoded><![CDATA[
快手在召回场景GPT范式的尝试
]]></content:encoded>
<pubDate>2024-05-20T12:39:23.000Z</pubDate>
</item>
<item>
<title>一文逮尽知名开源大模型作弊！训题库...</title>
<link>https://mp.weixin.qq.com/s/-o9pfWuEzALZfaTdNj_eXg</link>
<guid>https://mp.weixin.qq.com/s/-o9pfWuEzALZfaTdNj_eXg</guid>
<content:encoded><![CDATA[
一文逮尽知名开源大模型作弊！训题库...
]]></content:encoded>
<pubDate>2024-05-20T12:39:23.000Z</pubDate>
</item>
<item>
<title>大模型预训练认知分享</title>
<link>https://mp.weixin.qq.com/s/glByFfjEzbrTg9WQL3M1JQ</link>
<guid>https://mp.weixin.qq.com/s/glByFfjEzbrTg9WQL3M1JQ</guid>
<content:encoded><![CDATA[
<div> 大模型、预训练、认知、分享、文章
<br />
<br />
总结:本文介绍了大模型预训练的重要性和应用。大模型具有更强大的学习能力和泛化能力，可以对海量数据进行深度学习。预训练是一种有效的模型训练方法，可以在大数据集上训练模型，然后在特定任务上进行微调。认知方面，大模型预训练可以提高模型的理解能力和复杂任务的执行能力。分享方面，研究人员可以分享预训练模型和经验，促进模型的改进和发展。通过大模型预训练，可以取得更好的性能和效果，推动人工智能领域的发展。 <div>
大模型预训练认知分享
]]></content:encoded>
<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>Blurr AI 招聘RAG 研发工程师和AI Agent 开发工程师</title>
<link>https://mp.weixin.qq.com/s/nzHmEFZVevkrL5yfjTjJ2A</link>
<guid>https://mp.weixin.qq.com/s/nzHmEFZVevkrL5yfjTjJ2A</guid>
<content:encoded><![CDATA[
<div> AI、招聘、RAG、研发工程师、AI Agent
<br />
招聘Blurr AI公司的RAG研发工程师和AI Agent开发工程师。想要加入该公司的候选人需要有相关经验和技能，能够参与在人工智能领域的创新研发工作。公司给予员工发展和成长的机会，提供良好的工作环境和晋升机会。如果你对人工智能领域充满热情并具备相关技能和经验，欢迎加入Blurr AI团队。 <div>
Blurr AI 招聘RAG 研发工程师和AI Agent 开发工程师
]]></content:encoded>
<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>如何提升大模型RAG系统的效果？RAG推理增强(二)</title>
<link>https://mp.weixin.qq.com/s/PYMtVjZq0d_CfQN-zFdqCg</link>
<guid>https://mp.weixin.qq.com/s/PYMtVjZq0d_CfQN-zFdqCg</guid>
<content:encoded><![CDATA[
如何提升大模型RAG系统的效果？RAG推理增强(二)
]]></content:encoded>
<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>基于多模态信息抽取的菜品知识图谱构建</title>
<link>https://mp.weixin.qq.com/s/o0PsuyRGsBAZ1fR7XsHUDA</link>
<guid>https://mp.weixin.qq.com/s/o0PsuyRGsBAZ1fR7XsHUDA</guid>
<content:encoded><![CDATA[
基于多模态信息抽取的菜品知识图谱构建
]]></content:encoded>
<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>新加坡提示工程大赛冠军最强Prompt工程技巧分享，仅用大模型也能做数据分析</title>
<link>https://mp.weixin.qq.com/s/q3zjYV1R-s4a6LaFwaB9OQ</link>
<guid>https://mp.weixin.qq.com/s/q3zjYV1R-s4a6LaFwaB9OQ</guid>
<content:encoded><![CDATA[
新加坡提示工程大赛冠军最强Prompt工程技巧分享，仅用大模型也能做数据分析
]]></content:encoded>
<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>RAG还是微调？大模型微调技术全面盘点</title>
<link>https://mp.weixin.qq.com/s/KJ4qQWnF4rcJjz705ngCAQ</link>
<guid>https://mp.weixin.qq.com/s/KJ4qQWnF4rcJjz705ngCAQ</guid>
<content:encoded><![CDATA[
<div> RAG 微调 模型 技术 全面

<br /><br />总结:
本文全面盘点了微调大模型的技术，探讨了RAG和微调之间的关系。大模型微调技术的发展已经日益成熟，可以有效提升模型性能。RAG模型可以帮助用户更好地理解模型预测结果，尤其在自然语言处理领域表现突出。整体上，微调大模型是为了更好地适应特定任务，提高模型的准确性和泛化能力。通过深入研究大模型微调技术，可以更好地利用现有模型，为各类应用提供更好的解决方案。 <div>
RAG还是微调？大模型微调技术全面盘点
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>如何提升大模型的Agent推理规划等能力？</title>
<link>https://mp.weixin.qq.com/s/7208b2TxskVJn3IKj6hw6Q</link>
<guid>https://mp.weixin.qq.com/s/7208b2TxskVJn3IKj6hw6Q</guid>
<content:encoded><![CDATA[
<div> 提升 大模型 Agent 推理 规划 能力  
总结:  
提升大模型的Agent推理规划等能力，可采用以下策略：   
1. 引入更多数据：通过增加训练数据量，让Agent在更多场景中学习并提升推理能力。  
2. 增加模型复杂度：适当增加Agent的模型复杂度，提高推理和规划的精度和准确度。  
3. 优化算法：选择更优的优化算法，提高Agent的训练效率和模型性能。  
4. 强化学习：利用强化学习技术，让Agent在实时环境中不断优化策略和决策能力。  
5. 结合领域知识：结合实际领域的专业知识，让Agent更好地理解和处理复杂情况，提升推理规划能力。 <div>
如何提升大模型的Agent推理规划等能力？
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>开源闭源争论不休，浅谈大模型开源和闭源</title>
<link>https://mp.weixin.qq.com/s/y9Ru6UANWOu4Q2wHJBgMWQ</link>
<guid>https://mp.weixin.qq.com/s/y9Ru6UANWOu4Q2wHJBgMWQ</guid>
<content:encoded><![CDATA[
开源闭源争论不休，浅谈大模型开源和闭源
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>大模型测试集作弊？ICLR论文将leak一网打尽！</title>
<link>https://mp.weixin.qq.com/s/tGVB1f6oJ_-BJv88oFy8Uw</link>
<guid>https://mp.weixin.qq.com/s/tGVB1f6oJ_-BJv88oFy8Uw</guid>
<content:encoded><![CDATA[
大模型测试集作弊？ICLR论文将leak一网打尽！
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>IJCAI2024｜基于指令的大模型知识编辑</title>
<link>https://mp.weixin.qq.com/s/aMqcZW55I8xQrtpCy_nE_Q</link>
<guid>https://mp.weixin.qq.com/s/aMqcZW55I8xQrtpCy_nE_Q</guid>
<content:encoded><![CDATA[
IJCAI2024｜基于指令的大模型知识编辑
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>Transformer登上nature，被誉为大模型基石的它到底凭什么这么火？</title>
<link>https://mp.weixin.qq.com/s/xZneDM3IJlK4BfEASw1egg</link>
<guid>https://mp.weixin.qq.com/s/xZneDM3IJlK4BfEASw1egg</guid>
<content:encoded><![CDATA[
<div> Transformer 大模型 基石 火
<br />
总结:<br />
Transformer因其强大的处理能力和广泛的应用领域而受到广泛关注。作为大模型的基石，Transformer在自然语言处理等领域展现出了卓越的表现。其独特的结构和先进的机制使其能够有效地处理各种复杂任务，并取得令人瞩目的成果。Transformer的火爆也源于其被广泛认可为推动人工智能发展的关键技术之一，对未来的发展具有重要意义。 <div>
Transformer登上nature，被誉为大模型基石的它到底凭什么这么火？
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>手撕Flash Attention！原理解析及代码实现</title>
<link>https://mp.weixin.qq.com/s/2hSNQk1y99YM4TX0D96POQ</link>
<guid>https://mp.weixin.qq.com/s/2hSNQk1y99YM4TX0D96POQ</guid>
<content:encoded><![CDATA[
<div> 原理解析、代码实现、Flash、手撕、注意事项
<br />
手撕Flash Attention！是一篇介绍如何手动实现Flash Attention机制的文章。通过深入分析Flash Attention的原理，在代码中实现该机制，可以提高模型的性能和泛化能力。在实现过程中，需要注意调整超参数、保持网络结构的稳定性和正确使用损失函数等细节。通过手动实现Flash Attention，可以更好地理解模型内部的运作机制，从而更好地优化模型的表现。<br /><br />总结:手撕Flash Attention！是一篇介绍如何手动实现Flash Attention机制的文章。通过深入分析Flash Attention的原理，在代码中实现该机制，可以提高模型的性能和泛化能力。在实现过程中，需要注意调整超参数、保持网络结构的稳定性和正确使用损失函数等细节。 <div>
手撕Flash Attention！原理解析及代码实现
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>DPO作者新作｜From r to Q*</title>
<link>https://mp.weixin.qq.com/s/kRhatwbCyPFSl4tTxg_dlA</link>
<guid>https://mp.weixin.qq.com/s/kRhatwbCyPFSl4tTxg_dlA</guid>
<content:encoded><![CDATA[
DPO作者新作｜From r to Q*
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>Introducing GPT-4o</title>
<link>https://mp.weixin.qq.com/s/1Mvwf_U0NXq-1DDRjrd_uw</link>
<guid>https://mp.weixin.qq.com/s/1Mvwf_U0NXq-1DDRjrd_uw</guid>
<content:encoded><![CDATA[
Introducing GPT-4o
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>RAG开源项目Qanything源码阅读2-离线文件处理</title>
<link>https://mp.weixin.qq.com/s/MU4AwDWNZtoLkTIfvN5JZg</link>
<guid>https://mp.weixin.qq.com/s/MU4AwDWNZtoLkTIfvN5JZg</guid>
<content:encoded><![CDATA[
RAG开源项目Qanything源码阅读2-离线文件处理
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>太强了！深度学习融合魔改</title>
<link>https://mp.weixin.qq.com/s/HwJPnEdtYyPWuao-he6d1Q</link>
<guid>https://mp.weixin.qq.com/s/HwJPnEdtYyPWuao-he6d1Q</guid>
<content:encoded><![CDATA[
<div> 深度学习 魔改 融合 强大 技术<br />
<br />
总结:本文讨论了深度学习技术融合魔改的强大表现。通过对深度学习模型进行魔改，可以进一步提升其性能和效果。这种融合技术让深度学习在各个领域都表现出色，展现出强大的应用潜力。深度学习融合魔改的发展趋势令人振奋，将为科技创新带来新的契机和可能性。 <div>
太强了！深度学习融合魔改
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>LLM落地淘宝电商搜索场景，显著提升长尾query改写效果</title>
<link>https://mp.weixin.qq.com/s/VYiSkPwYz2UJGHyu36H0zg</link>
<guid>https://mp.weixin.qq.com/s/VYiSkPwYz2UJGHyu36H0zg</guid>
<content:encoded><![CDATA[
<div> LLM、淘宝电商、搜索场景、长尾query、改写效果

<br /><br />总结:
文章介绍了如何利用LLM（Language Model for Large-scale Retrieval）技术来落地至淘宝电商搜索场景，以显著提升长尾query的改写效果。首先，作者提到了LLM技术的优势和应用场景，然后详细解释了在淘宝电商搜索中如何应用LLM来改写长尾query以提升搜索结果的准确性和覆盖范围。通过实际案例分析和实验结果展示，可以看出LLM在淘宝电商场景中的有效性和实用性。最后，作者总结了LLM在电商搜索场景中的应用前景和潜力，为提升用户搜索体验和推动电商发展提供了有益启示。 <div>
LLM落地淘宝电商搜索场景，显著提升长尾query改写效果
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>StarCoder2-Instruct: 完全透明和可自我对齐的代码生成</title>
<link>https://mp.weixin.qq.com/s/jcTpFWeW18Dkc19jhesGag</link>
<guid>https://mp.weixin.qq.com/s/jcTpFWeW18Dkc19jhesGag</guid>
<content:encoded><![CDATA[
StarCoder2-Instruct: 完全透明和可自我对齐的代码生成
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>零一万物开源Yi-1.5系列大模型</title>
<link>https://mp.weixin.qq.com/s/ltUsEHFAOCJ56YW9devhPg</link>
<guid>https://mp.weixin.qq.com/s/ltUsEHFAOCJ56YW9devhPg</guid>
<content:encoded><![CDATA[
零一万物开源Yi-1.5系列大模型
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>COLING24 ｜无需标注即可增强模型 COT 能力</title>
<link>https://mp.weixin.qq.com/s/hrOo_42qmWsPawMYZOQ7eg</link>
<guid>https://mp.weixin.qq.com/s/hrOo_42qmWsPawMYZOQ7eg</guid>
<content:encoded><![CDATA[
COLING24 ｜无需标注即可增强模型 COT 能力
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>终于知道工资为什么要保密了。</title>
<link>https://mp.weixin.qq.com/s/ejCN1cFhIzjGAsifqMgD9Q</link>
<guid>https://mp.weixin.qq.com/s/ejCN1cFhIzjGAsifqMgD9Q</guid>
<content:encoded><![CDATA[
<div> 保密、工资、知道、原因、重要<br />
<br />
重要性在于工资保密可以避免引起员工之间的比较和不必要的矛盾，保持工作环境的和谐稳定。另外，工资涉及到公司的商业机密和绩效考核等信息，如果泄露出去可能会对公司造成不利影响。同时，保密也可以提高员工的安全感，让他们更专注于工作内容而非薪酬问题。最后，明确规定工资保密也有利于建立公司的信任和合作氛围，确保员工团队的团结和凝聚力。总结: 工资保密的重要性体现在避免矛盾、保护商业机密、提高员工安全感、建立信任和合作氛围。 <div>
终于知道工资为什么要保密了。
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>【文末赠书】大语言模型的生态系统</title>
<link>https://mp.weixin.qq.com/s/-zdHnNz6YXJsLWwq_dik8g</link>
<guid>https://mp.weixin.qq.com/s/-zdHnNz6YXJsLWwq_dik8g</guid>
<content:encoded><![CDATA[
<div> 生态系统、大语言模型、发展、应用、影响<br />
<br />
总结: 大语言模型作为生态系统中重要的一部分，不断发展并广泛应用于各个领域。其强大的语言生成能力和智能化特性影响着人们的生活和工作方式。随着技术不断进步，大语言模型的应用范围将会不断扩大，为社会发展和创新带来更多可能性。 <div>
【文末赠书】大语言模型的生态系统
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>阿里通义-对话智能团队实习生(Research Intern)招聘​</title>
<link>https://mp.weixin.qq.com/s/Oj1tRDMVRJ2fiJjOnbyd1Q</link>
<guid>https://mp.weixin.qq.com/s/Oj1tRDMVRJ2fiJjOnbyd1Q</guid>
<content:encoded><![CDATA[
阿里通义-对话智能团队实习生(Research Intern)招聘​
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>利用知识图谱提升RAG应用的准确性</title>
<link>https://mp.weixin.qq.com/s/TZ22SyF74YOJwoIZeaRDcA</link>
<guid>https://mp.weixin.qq.com/s/TZ22SyF74YOJwoIZeaRDcA</guid>
<content:encoded><![CDATA[
利用知识图谱提升RAG应用的准确性
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>“Ruozhiba” is all you need</title>
<link>https://mp.weixin.qq.com/s/CDKGlOUTz6HqceRO1ESOUA</link>
<guid>https://mp.weixin.qq.com/s/CDKGlOUTz6HqceRO1ESOUA</guid>
<content:encoded><![CDATA[
“Ruozhiba” is all you need
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>为什么这次AlphaFold3再次意义非凡？</title>
<link>https://mp.weixin.qq.com/s/Gl_tHdu5pBl8Wfjl2FRkLQ</link>
<guid>https://mp.weixin.qq.com/s/Gl_tHdu5pBl8Wfjl2FRkLQ</guid>
<content:encoded><![CDATA[
为什么这次AlphaFold3再次意义非凡？
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
<item>
<title>大模型推理窗口-从有限到无限大</title>
<link>https://mp.weixin.qq.com/s/ogrWe61JZz64FXTcBfVN5Q</link>
<guid>https://mp.weixin.qq.com/s/ogrWe61JZz64FXTcBfVN5Q</guid>
<content:encoded><![CDATA[
大模型推理窗口-从有限到无限大
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
<item>
<title>AI搜索与大模型应用的一些思考</title>
<link>https://mp.weixin.qq.com/s/ZSHGUT6FMtcGD62d5RInuw</link>
<guid>https://mp.weixin.qq.com/s/ZSHGUT6FMtcGD62d5RInuw</guid>
<content:encoded><![CDATA[
AI搜索与大模型应用的一些思考
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
<item>
<title>南方科技大学统计与数据科学系 &amp; 香港中文大学（深圳）数据科学学院联合招聘</title>
<link>https://mp.weixin.qq.com/s/Hm24CLClwqukkgk8qtgv1A</link>
<guid>https://mp.weixin.qq.com/s/Hm24CLClwqukkgk8qtgv1A</guid>
<content:encoded><![CDATA[
南方科技大学统计与数据科学系 & 香港中文大学（深圳）数据科学学院联合招聘
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
<item>
<title>SIGIR2024｜现实场景下的多模态知识图谱补全</title>
<link>https://mp.weixin.qq.com/s/fWXxyQgYp8gf3o6WW2gY4Q</link>
<guid>https://mp.weixin.qq.com/s/fWXxyQgYp8gf3o6WW2gY4Q</guid>
<content:encoded><![CDATA[
SIGIR2024｜现实场景下的多模态知识图谱补全
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
</channel>
</rss>