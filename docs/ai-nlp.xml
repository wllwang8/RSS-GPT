<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>AINLP</title>
<link>http://tw.wleilei.com:4001/feeds/MP_WXS_2398933301.atom</link>

<item>
<title>大模型预训练认知分享</title>
<link>https://mp.weixin.qq.com/s/glByFfjEzbrTg9WQL3M1JQ</link>
<guid>https://mp.weixin.qq.com/s/glByFfjEzbrTg9WQL3M1JQ</guid>
<content:encoded><![CDATA[
<div> 大模型、预训练、认知、分享、文章
<br>
<br>
总结:本文介绍了大模型预训练的重要性和应用。大模型具有更强大的学习能力和泛化能力，可以对海量数据进行深度学习。预训练是一种有效的模型训练方法，可以在大数据集上训练模型，然后在特定任务上进行微调。认知方面，大模型预训练可以提高模型的理解能力和复杂任务的执行能力。分享方面，研究人员可以分享预训练模型和经验，促进模型的改进和发展。通过大模型预训练，可以取得更好的性能和效果，推动人工智能领域的发展。 <div>
大模型预训练认知分享
]]></content:encoded>

<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>Blurr AI 招聘RAG 研发工程师和AI Agent 开发工程师</title>
<link>https://mp.weixin.qq.com/s/nzHmEFZVevkrL5yfjTjJ2A</link>
<guid>https://mp.weixin.qq.com/s/nzHmEFZVevkrL5yfjTjJ2A</guid>
<content:encoded><![CDATA[
<div> AI、招聘、RAG、研发工程师、AI Agent
<br>
招聘Blurr AI公司的RAG研发工程师和AI Agent开发工程师。想要加入该公司的候选人需要有相关经验和技能，能够参与在人工智能领域的创新研发工作。公司给予员工发展和成长的机会，提供良好的工作环境和晋升机会。如果你对人工智能领域充满热情并具备相关技能和经验，欢迎加入Blurr AI团队。 <div>
Blurr AI 招聘RAG 研发工程师和AI Agent 开发工程师
]]></content:encoded>

<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>如何提升大模型RAG系统的效果？RAG推理增强(二)</title>
<link>https://mp.weixin.qq.com/s/PYMtVjZq0d_CfQN-zFdqCg</link>
<guid>https://mp.weixin.qq.com/s/PYMtVjZq0d_CfQN-zFdqCg</guid>
<content:encoded><![CDATA[

如何提升大模型RAG系统的效果？RAG推理增强(二)
]]></content:encoded>

<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>基于多模态信息抽取的菜品知识图谱构建</title>
<link>https://mp.weixin.qq.com/s/o0PsuyRGsBAZ1fR7XsHUDA</link>
<guid>https://mp.weixin.qq.com/s/o0PsuyRGsBAZ1fR7XsHUDA</guid>
<content:encoded><![CDATA[

基于多模态信息抽取的菜品知识图谱构建
]]></content:encoded>

<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>
<item>
<title>新加坡提示工程大赛冠军最强Prompt工程技巧分享，仅用大模型也能做数据分析</title>
<link>https://mp.weixin.qq.com/s/q3zjYV1R-s4a6LaFwaB9OQ</link>
<guid>https://mp.weixin.qq.com/s/q3zjYV1R-s4a6LaFwaB9OQ</guid>
<content:encoded><![CDATA[

新加坡提示工程大赛冠军最强Prompt工程技巧分享，仅用大模型也能做数据分析
]]></content:encoded>

<pubDate>2024-05-17T13:15:13.000Z</pubDate>
</item>

<item>
<title>RAG还是微调？大模型微调技术全面盘点</title>
<link>https://mp.weixin.qq.com/s/KJ4qQWnF4rcJjz705ngCAQ</link>
<guid>https://mp.weixin.qq.com/s/KJ4qQWnF4rcJjz705ngCAQ</guid>
<content:encoded><![CDATA[
<div> RAG 微调 模型 技术 全面

<br /><br />总结:
本文全面盘点了微调大模型的技术，探讨了RAG和微调之间的关系。大模型微调技术的发展已经日益成熟，可以有效提升模型性能。RAG模型可以帮助用户更好地理解模型预测结果，尤其在自然语言处理领域表现突出。整体上，微调大模型是为了更好地适应特定任务，提高模型的准确性和泛化能力。通过深入研究大模型微调技术，可以更好地利用现有模型，为各类应用提供更好的解决方案。 <div>
RAG还是微调？大模型微调技术全面盘点
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>如何提升大模型的Agent推理规划等能力？</title>
<link>https://mp.weixin.qq.com/s/7208b2TxskVJn3IKj6hw6Q</link>
<guid>https://mp.weixin.qq.com/s/7208b2TxskVJn3IKj6hw6Q</guid>
<content:encoded><![CDATA[
<div> 提升 大模型 Agent 推理 规划 能力  
总结:  
提升大模型的Agent推理规划等能力，可采用以下策略：   
1. 引入更多数据：通过增加训练数据量，让Agent在更多场景中学习并提升推理能力。  
2. 增加模型复杂度：适当增加Agent的模型复杂度，提高推理和规划的精度和准确度。  
3. 优化算法：选择更优的优化算法，提高Agent的训练效率和模型性能。  
4. 强化学习：利用强化学习技术，让Agent在实时环境中不断优化策略和决策能力。  
5. 结合领域知识：结合实际领域的专业知识，让Agent更好地理解和处理复杂情况，提升推理规划能力。 <div>
如何提升大模型的Agent推理规划等能力？
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>开源闭源争论不休，浅谈大模型开源和闭源</title>
<link>https://mp.weixin.qq.com/s/y9Ru6UANWOu4Q2wHJBgMWQ</link>
<guid>https://mp.weixin.qq.com/s/y9Ru6UANWOu4Q2wHJBgMWQ</guid>
<content:encoded><![CDATA[
开源闭源争论不休，浅谈大模型开源和闭源
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>大模型测试集作弊？ICLR论文将leak一网打尽！</title>
<link>https://mp.weixin.qq.com/s/tGVB1f6oJ_-BJv88oFy8Uw</link>
<guid>https://mp.weixin.qq.com/s/tGVB1f6oJ_-BJv88oFy8Uw</guid>
<content:encoded><![CDATA[
大模型测试集作弊？ICLR论文将leak一网打尽！
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>IJCAI2024｜基于指令的大模型知识编辑</title>
<link>https://mp.weixin.qq.com/s/aMqcZW55I8xQrtpCy_nE_Q</link>
<guid>https://mp.weixin.qq.com/s/aMqcZW55I8xQrtpCy_nE_Q</guid>
<content:encoded><![CDATA[
IJCAI2024｜基于指令的大模型知识编辑
]]></content:encoded>
<pubDate>2024-05-15T14:21:35.000Z</pubDate>
</item>
<item>
<title>Transformer登上nature，被誉为大模型基石的它到底凭什么这么火？</title>
<link>https://mp.weixin.qq.com/s/xZneDM3IJlK4BfEASw1egg</link>
<guid>https://mp.weixin.qq.com/s/xZneDM3IJlK4BfEASw1egg</guid>
<content:encoded><![CDATA[
<div> Transformer 大模型 基石 火
<br />
总结:<br />
Transformer因其强大的处理能力和广泛的应用领域而受到广泛关注。作为大模型的基石，Transformer在自然语言处理等领域展现出了卓越的表现。其独特的结构和先进的机制使其能够有效地处理各种复杂任务，并取得令人瞩目的成果。Transformer的火爆也源于其被广泛认可为推动人工智能发展的关键技术之一，对未来的发展具有重要意义。 <div>
Transformer登上nature，被誉为大模型基石的它到底凭什么这么火？
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>手撕Flash Attention！原理解析及代码实现</title>
<link>https://mp.weixin.qq.com/s/2hSNQk1y99YM4TX0D96POQ</link>
<guid>https://mp.weixin.qq.com/s/2hSNQk1y99YM4TX0D96POQ</guid>
<content:encoded><![CDATA[
<div> 原理解析、代码实现、Flash、手撕、注意事项
<br />
手撕Flash Attention！是一篇介绍如何手动实现Flash Attention机制的文章。通过深入分析Flash Attention的原理，在代码中实现该机制，可以提高模型的性能和泛化能力。在实现过程中，需要注意调整超参数、保持网络结构的稳定性和正确使用损失函数等细节。通过手动实现Flash Attention，可以更好地理解模型内部的运作机制，从而更好地优化模型的表现。<br /><br />总结:手撕Flash Attention！是一篇介绍如何手动实现Flash Attention机制的文章。通过深入分析Flash Attention的原理，在代码中实现该机制，可以提高模型的性能和泛化能力。在实现过程中，需要注意调整超参数、保持网络结构的稳定性和正确使用损失函数等细节。 <div>
手撕Flash Attention！原理解析及代码实现
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>DPO作者新作｜From r to Q*</title>
<link>https://mp.weixin.qq.com/s/kRhatwbCyPFSl4tTxg_dlA</link>
<guid>https://mp.weixin.qq.com/s/kRhatwbCyPFSl4tTxg_dlA</guid>
<content:encoded><![CDATA[
DPO作者新作｜From r to Q*
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>Introducing GPT-4o</title>
<link>https://mp.weixin.qq.com/s/1Mvwf_U0NXq-1DDRjrd_uw</link>
<guid>https://mp.weixin.qq.com/s/1Mvwf_U0NXq-1DDRjrd_uw</guid>
<content:encoded><![CDATA[
Introducing GPT-4o
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>RAG开源项目Qanything源码阅读2-离线文件处理</title>
<link>https://mp.weixin.qq.com/s/MU4AwDWNZtoLkTIfvN5JZg</link>
<guid>https://mp.weixin.qq.com/s/MU4AwDWNZtoLkTIfvN5JZg</guid>
<content:encoded><![CDATA[
RAG开源项目Qanything源码阅读2-离线文件处理
]]></content:encoded>
<pubDate>2024-05-14T15:12:33.000Z</pubDate>
</item>
<item>
<title>太强了！深度学习融合魔改</title>
<link>https://mp.weixin.qq.com/s/HwJPnEdtYyPWuao-he6d1Q</link>
<guid>https://mp.weixin.qq.com/s/HwJPnEdtYyPWuao-he6d1Q</guid>
<content:encoded><![CDATA[
<div> 深度学习 魔改 融合 强大 技术<br />
<br />
总结:本文讨论了深度学习技术融合魔改的强大表现。通过对深度学习模型进行魔改，可以进一步提升其性能和效果。这种融合技术让深度学习在各个领域都表现出色，展现出强大的应用潜力。深度学习融合魔改的发展趋势令人振奋，将为科技创新带来新的契机和可能性。 <div>
太强了！深度学习融合魔改
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>LLM落地淘宝电商搜索场景，显著提升长尾query改写效果</title>
<link>https://mp.weixin.qq.com/s/VYiSkPwYz2UJGHyu36H0zg</link>
<guid>https://mp.weixin.qq.com/s/VYiSkPwYz2UJGHyu36H0zg</guid>
<content:encoded><![CDATA[
<div> LLM、淘宝电商、搜索场景、长尾query、改写效果

<br /><br />总结:
文章介绍了如何利用LLM（Language Model for Large-scale Retrieval）技术来落地至淘宝电商搜索场景，以显著提升长尾query的改写效果。首先，作者提到了LLM技术的优势和应用场景，然后详细解释了在淘宝电商搜索中如何应用LLM来改写长尾query以提升搜索结果的准确性和覆盖范围。通过实际案例分析和实验结果展示，可以看出LLM在淘宝电商场景中的有效性和实用性。最后，作者总结了LLM在电商搜索场景中的应用前景和潜力，为提升用户搜索体验和推动电商发展提供了有益启示。 <div>
LLM落地淘宝电商搜索场景，显著提升长尾query改写效果
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>StarCoder2-Instruct: 完全透明和可自我对齐的代码生成</title>
<link>https://mp.weixin.qq.com/s/jcTpFWeW18Dkc19jhesGag</link>
<guid>https://mp.weixin.qq.com/s/jcTpFWeW18Dkc19jhesGag</guid>
<content:encoded><![CDATA[
StarCoder2-Instruct: 完全透明和可自我对齐的代码生成
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>零一万物开源Yi-1.5系列大模型</title>
<link>https://mp.weixin.qq.com/s/ltUsEHFAOCJ56YW9devhPg</link>
<guid>https://mp.weixin.qq.com/s/ltUsEHFAOCJ56YW9devhPg</guid>
<content:encoded><![CDATA[
零一万物开源Yi-1.5系列大模型
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>COLING24 ｜无需标注即可增强模型 COT 能力</title>
<link>https://mp.weixin.qq.com/s/hrOo_42qmWsPawMYZOQ7eg</link>
<guid>https://mp.weixin.qq.com/s/hrOo_42qmWsPawMYZOQ7eg</guid>
<content:encoded><![CDATA[
COLING24 ｜无需标注即可增强模型 COT 能力
]]></content:encoded>
<pubDate>2024-05-13T14:35:24.000Z</pubDate>
</item>
<item>
<title>终于知道工资为什么要保密了。</title>
<link>https://mp.weixin.qq.com/s/ejCN1cFhIzjGAsifqMgD9Q</link>
<guid>https://mp.weixin.qq.com/s/ejCN1cFhIzjGAsifqMgD9Q</guid>
<content:encoded><![CDATA[
<div> 保密、工资、知道、原因、重要<br />
<br />
重要性在于工资保密可以避免引起员工之间的比较和不必要的矛盾，保持工作环境的和谐稳定。另外，工资涉及到公司的商业机密和绩效考核等信息，如果泄露出去可能会对公司造成不利影响。同时，保密也可以提高员工的安全感，让他们更专注于工作内容而非薪酬问题。最后，明确规定工资保密也有利于建立公司的信任和合作氛围，确保员工团队的团结和凝聚力。总结: 工资保密的重要性体现在避免矛盾、保护商业机密、提高员工安全感、建立信任和合作氛围。 <div>
终于知道工资为什么要保密了。
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>【文末赠书】大语言模型的生态系统</title>
<link>https://mp.weixin.qq.com/s/-zdHnNz6YXJsLWwq_dik8g</link>
<guid>https://mp.weixin.qq.com/s/-zdHnNz6YXJsLWwq_dik8g</guid>
<content:encoded><![CDATA[
<div> 生态系统、大语言模型、发展、应用、影响<br />
<br />
总结: 大语言模型作为生态系统中重要的一部分，不断发展并广泛应用于各个领域。其强大的语言生成能力和智能化特性影响着人们的生活和工作方式。随着技术不断进步，大语言模型的应用范围将会不断扩大，为社会发展和创新带来更多可能性。 <div>
【文末赠书】大语言模型的生态系统
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>阿里通义-对话智能团队实习生(Research Intern)招聘​</title>
<link>https://mp.weixin.qq.com/s/Oj1tRDMVRJ2fiJjOnbyd1Q</link>
<guid>https://mp.weixin.qq.com/s/Oj1tRDMVRJ2fiJjOnbyd1Q</guid>
<content:encoded><![CDATA[
阿里通义-对话智能团队实习生(Research Intern)招聘​
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>利用知识图谱提升RAG应用的准确性</title>
<link>https://mp.weixin.qq.com/s/TZ22SyF74YOJwoIZeaRDcA</link>
<guid>https://mp.weixin.qq.com/s/TZ22SyF74YOJwoIZeaRDcA</guid>
<content:encoded><![CDATA[
利用知识图谱提升RAG应用的准确性
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>“Ruozhiba” is all you need</title>
<link>https://mp.weixin.qq.com/s/CDKGlOUTz6HqceRO1ESOUA</link>
<guid>https://mp.weixin.qq.com/s/CDKGlOUTz6HqceRO1ESOUA</guid>
<content:encoded><![CDATA[
“Ruozhiba” is all you need
]]></content:encoded>
<pubDate>2024-05-12T13:56:41.000Z</pubDate>
</item>
<item>
<title>为什么这次AlphaFold3再次意义非凡？</title>
<link>https://mp.weixin.qq.com/s/Gl_tHdu5pBl8Wfjl2FRkLQ</link>
<guid>https://mp.weixin.qq.com/s/Gl_tHdu5pBl8Wfjl2FRkLQ</guid>
<content:encoded><![CDATA[
为什么这次AlphaFold3再次意义非凡？
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
<item>
<title>大模型推理窗口-从有限到无限大</title>
<link>https://mp.weixin.qq.com/s/ogrWe61JZz64FXTcBfVN5Q</link>
<guid>https://mp.weixin.qq.com/s/ogrWe61JZz64FXTcBfVN5Q</guid>
<content:encoded><![CDATA[
大模型推理窗口-从有限到无限大
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
<item>
<title>AI搜索与大模型应用的一些思考</title>
<link>https://mp.weixin.qq.com/s/ZSHGUT6FMtcGD62d5RInuw</link>
<guid>https://mp.weixin.qq.com/s/ZSHGUT6FMtcGD62d5RInuw</guid>
<content:encoded><![CDATA[
AI搜索与大模型应用的一些思考
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
<item>
<title>南方科技大学统计与数据科学系 &amp; 香港中文大学（深圳）数据科学学院联合招聘</title>
<link>https://mp.weixin.qq.com/s/Hm24CLClwqukkgk8qtgv1A</link>
<guid>https://mp.weixin.qq.com/s/Hm24CLClwqukkgk8qtgv1A</guid>
<content:encoded><![CDATA[
南方科技大学统计与数据科学系 & 香港中文大学（深圳）数据科学学院联合招聘
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
<item>
<title>SIGIR2024｜现实场景下的多模态知识图谱补全</title>
<link>https://mp.weixin.qq.com/s/fWXxyQgYp8gf3o6WW2gY4Q</link>
<guid>https://mp.weixin.qq.com/s/fWXxyQgYp8gf3o6WW2gY4Q</guid>
<content:encoded><![CDATA[
SIGIR2024｜现实场景下的多模态知识图谱补全
]]></content:encoded>
<pubDate>2024-05-10T12:17:53.000Z</pubDate>
</item>
</channel>
</rss>