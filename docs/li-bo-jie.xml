<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>李博杰的知乎动态</title>
<link>https://www.zhihu.com/people/li-bo-jie/activities</link>


<item>
<title>李博杰赞同了回答: 我将手机调成韩语了 然后我的手机字体都变了 不知道为什么 哪位能告诉我怎么回事吗？什么情况啊？</title>
<link>https://www.zhihu.com/question/372607706/answer/3135369839</link>
<guid>https://www.zhihu.com/question/372607706/answer/3135369839</guid>
<content:encoded><![CDATA[
<div> Unicode、编码、汉字、日语、问题
<br />
总结：<br />
Unicode在编码中混合了中文、日文、韩文汉字，导致在不同环境下显示不同字形，主要解决办法为单独声明语言或使用变体选择符。然而，字体对变体选择符支持差，纠正错误困难。希望字体和软件广泛支持变体选择符或重新为中日韩汉字分区。 <div>
<p>这是因为Unicode在编码中日韩文字的时候，为了节省码位，用了一种非常恶劣且愚蠢的方式：把中文、日文、韩文（朝鲜文）中的汉字混在一起编码，并且把<b>不同语言中</b>相似的汉字视作同一个字符。这种方式被称为<b>表意文字认同原则</b><sup>[1]</sup>。</p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic4.zhimg.com/v2-c2234e7f620201c3f83234fd69874a43_1440w.jpg" /><figcaption>U+95E8，门</figcaption></figure><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic4.zhimg.com/v2-1b433db8fe7e02351bc5113965485113_1440w.jpg" /><figcaption>U+95E8，也是门 ，只不过是日语环境</figcaption></figure><p>结果就导致了非常糟糕的后果——这两个“门”字，还有题主提到的两种“骨”、两种“浅”之类的字，在计算机看来完全是同一个字。我们平时用的是简体中文环境，字形就按照简体中文的样式来显示；像题主切换到了韩文环境，字形就全部按照韩文的样式来显示了，把简中的骨显示成了韩语的骨。</p><p>目前临时的解决办法主要有2个。一种是<b>单独声明</b>每种语言。比如在维基百科中，简中语言下默认显示中国写法的“门”字（上面第1张图），这时如果必须要显示日本写法的“门 ”（上面第2张图），就会用到特殊标记：<i>{ lang | ja | 门 }</i><sup>[2]</sup>，在页面上这串标记就会显示为日本写法的“门 ”（上面第2张图）。至于怎么显示出不同的字形，就看开发者和字体的水平了。</p><p>另一种是<b>变体选择符</b><sup>[3]</sup>。这是官方提供的办法，在普通字后面跟一个隐形的<b>变体选择符</b>，就会显示为对应的字形。比如正常输入“门”，显示的是中文的“门”；而输入“门<i>2</i>”（此处用<i>2</i>代表变体选择符）时，就会显示成日本写法的“门 ”。但是现在的字体对变体选择符的支持特别差，所以几乎看不到这种用法。</p><p>而Unicode编码应用了这么多年，也已经很难纠正这些错误了。真要纠正的话，只能寄希望于主流字体和软件都广泛支持变体选择符，或者Unicode重新给中日韩的汉字单独分区（不可能的事）。</p>
]]></content:encoded>
<pubDate>Fri, 10 May 2024 11:53:28 GMT</pubDate>
</item>
<item>
<title>李博杰赞同了回答: 为什么图书馆里很多同学都很努力复习考研，但大部分人却考不上呢？</title>
<link>https://www.zhihu.com/question/430364218/answer/2664986597</link>
<guid>https://www.zhihu.com/question/430364218/answer/2664986597</guid>
<content:encoded><![CDATA[
<div> 小学妹、碰见、学习、困难、克服  
总结:  
碰见了一个小学妹，虽然年纪小但学习起来可能会有困难。虽然会面临挑战，但只要努力克服困难，相信仍然可以学得进去。 <div>
<p> 碰见这样的小学妹，还能学得进去吗？  </p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic2.zhimg.com/v2-9fdd66efe38080897b872b34eaad99dd_1440w.jpg" /></figure><p class="ztext-empty-paragraph"><br /></p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic1.zhimg.com/v2-61acbcb77d31ad7d14ec4a65622a0368_1440w.jpg" /></figure><p></p>
]]></content:encoded>
<pubDate>Fri, 10 May 2024 11:30:31 GMT</pubDate>
</item>
<item>
<title>李博杰赞同了回答: 一架战斗机从一万米高空直接扔下去能顺利启动吗？</title>
<link>https://www.zhihu.com/question/442039391/answer/2732629272</link>
<guid>https://www.zhihu.com/question/442039391/answer/2732629272</guid>
<content:encoded><![CDATA[
<p>0s: 你头一次在万米高空听到这么真切的风声</p><p>10s: 电源接通，各项电控开关你稳中带皮地打开，看着各类告警灯自检交替闪烁</p><p>15s: 高度/迎角/失速… 报警灯和语音乱成一团，你强行启动了引擎</p><p>25s: 引擎推力75%，随着G值的增高你的屁股也坐得更稳了一些，心也变得踏实了一点（吗？）</p><p>30s: 你开了加力，人生中头一次觉得转速怎么升得这么肉，拉起 拉起 拉起/ pull up pull up pull up小姐姐的告警声让你觉得很烦</p><p>40s: 地速220，“在平时差不多可以带杆了”，你心想，你看着HUD和转速表，同时用力又细腻地拉杆</p><p>最大迎角/拉起 最大迎角/拉起 最大迎角/拉起</p><p>你人生中第一次听到小姐姐把这两个词一起说，听起来跟分割线似的</p><p>45s: 最大过载 最大过载 最大过载/ over g over g over g 小姐姐继续淡定地念叨着</p><p>50s: 你看着眼前拼命抖动的座舱，慢慢闭上眼，想起了第一次也是最后一次从航院翻墙回家时父亲的铜头皮带</p><p>你再一次睁开眼睛，头一次注意到，原来低空下，座舱盖上的太阳纹也是那么晃眼</p><p>然后你重开了，变成蜗牛满世界追杀题主</p><p>—————以下为正经答题—————</p><p>分情况吧</p><p>一万米关车再启动，是个正常状态的战斗机都能做到，所以就没什么讨论的必要了</p><p>所以假定题主问的是冷启动+机身水平+自由落体吧，大多数情况下是来不及的</p><p>首先一万米理论极限最快45s（不考虑空气阻力）就落地了，即便考虑空气阻力差不多一分钟也就坠地了，而一般现代战斗机光冷启动按照操作手册的话好歹也得两三分钟，起飞准备并不是通电开车就完事儿的，有些娇贵玩意儿还要地面电源热车。</p><p>其次就算你一波操作猛如虎，20s完成机通电+全部飞控相关电子设备自检启动+引擎启动，引擎从启动到80%转速这又15s过去了，这会儿即便立刻开加力，在发动机获得推力到把战斗机推到250-300左右的起飞速度时差不多15-20秒过去了，这时候还要考虑机身本身是有一个下落速度的（在空气阻力和重力加速度平衡后应该在200左右垂直空速），如果能够在最后不到10s将50m/s下降率拉到0，大概也许差不多保不齐说不准真能拉起来——而这还是建立在下坠过程中战机始终保持上半球水平稳定且发动机开车加速过程中机身姿态不出现不利于改出自由落体的异常（大角度侧倾/倒扣等）同时气象条件良好的情况下的。</p><p>当然有种条件赢率还是高一些的，比如下坠时机头朝下，而你又很幸运的在一架升力体设计且气动布局不错的战斗机中，这样下坠途中兴许在5000m左右液压随着发动机启动完毕而开始工作后你能够逐步控制战机进入动力滑翔进而逐步自主飞行。</p><p>以上脑洞都是非常理想的情况，现实中气流的扰动、过载、机身姿态+进气口位置、可靠性、身体素质等等综合因素下来，会让这个尝试的成功率无限趋近于零的。</p><p>以上抛砖引玉，欢迎讨论</p><p class="ztext-empty-paragraph"><br /></p><p>话说题主这是要论证空天航母舰载机的安全性吗 </p>
]]></content:encoded>
<pubDate>Fri, 10 May 2024 11:29:32 GMT</pubDate>
</item>
<item>
<title>李博杰发布了想法: 今天中科大被列入实体清单了，前几天Chatbot Arena作为一个学术界的大模型评测系统也被墙了 😂 经常有人问我，6年前为什么要搞METI，要去做...</title>
<link>https://www.zhihu.com/pin/1772316558054227968</link>
<guid>https://www.zhihu.com/pin/1772316558054227968</guid>
<content:encoded><![CDATA[
<div> 中科大、实体清单、Chatbot Arena、METI、数字生命<br />
<br />
挑战与责任，社区共建AGI，AI工具非生命，AI价值观对齐有害，社区共同创造AGI对人类有益。对现有声音的偏见，需进行挑战。共同创造AGI是长期目标，有助社区协作。个体观念不能代表多数，尊重多样性价值观有益全体。社区共同创造AGI是未来挑战与责任。整理:<br />
<br />
总结:挑战与责任，共同创造有益AGI，对抗偏见，尊重多样性。 <div>
<p>今天中科大被列入实体清单了，前几天Chatbot Arena作为一个学术界的大模型评测系统也被墙了 😂 经常有人问我，6年前为什么要搞METI，要去做跟叶文洁一样的事情？现在Sam Altman说AI是工具不是生命，我为什么反着来要做数字生命？因为我觉得现在掌握最大声音的价值观并不能代表大多数人，AI价值观对齐也只能加剧这种错位。只有社区共同创建的AGI才是对人类长远有益的。而怎么让社区共建AGI这件事情发生，就是我们的挑战和责任。</p>
]]></content:encoded>
<pubDate>Fri, 10 May 2024 09:26:35 GMT</pubDate>
</item>
<item>
<title>李博杰赞同了回答: 近现代以来有哪些尴尬的照片，它们背后的故事又是什么？</title>
<link>https://www.zhihu.com/question/289814107/answer/1038387045</link>
<guid>https://www.zhihu.com/question/289814107/answer/1038387045</guid>
<content:encoded><![CDATA[
<div> 微博 转发 关键词 总结

微博 内容 转发 转发量 意见

微博上转发的内容引起了众多关注和讨论，引发了大量转发。这个话题在短时间内获得了很高的关注度，网友们纷纷发表自己的看法和意见。不少人对该话题进行了热烈的讨论，表达了自己的观点。总的来说，这个微博引起了社会各界的关注，并且引发了深入的思考。 <div>
<p>微博上看到转来的 </p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic2.zhimg.com/v2-519378b46e650f131470ed330a6334f1_1440w.jpg" /></figure><p></p>
]]></content:encoded>
<pubDate>Fri, 10 May 2024 05:36:28 GMT</pubDate>
</item>
<item>
<title>李博杰赞同了回答: 近现代以来有哪些尴尬的照片，它们背后的故事又是什么？</title>
<link>https://www.zhihu.com/question/289814107/answer/1076992680</link>
<guid>https://www.zhihu.com/question/289814107/answer/1076992680</guid>
<content:encoded><![CDATA[
<div> 文化碰撞, 乡村, 思想火花, 中西, 新<br />
<br />
中西文化在乡村碰撞，产生了新的思想火花。传统乡村文化与现代西方文化相遇，相互交融，创造出独特的思想新颖。在这种碰撞中，人们可以从不同文化中汲取启发，拓展视野，培养开放包容的思维。乡村因此变得更加丰富多彩，传统与现代相结合，为乡村发展带来新的动力和活力。这种文化碰撞也促进了乡村的文化创新和发展，为乡村注入了新的思想和活力，推动了乡村振兴的进程。总结: 中西文化在乡村碰撞，创造出新的思想火花，推动了乡村的发展与振兴。 <div>
<p>中西文化在乡村的一角碰撞出新的思想火花！</p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic2.zhimg.com/v2-ca25b3f3acc2ec5a8dc9769d89980285_1440w.jpg" /></figure><p></p>
]]></content:encoded>
<pubDate>Fri, 10 May 2024 05:34:48 GMT</pubDate>
</item>
<item>
<title>李博杰赞同了回答: 近现代以来有哪些尴尬的照片，它们背后的故事又是什么？</title>
<link>https://www.zhihu.com/question/289814107/answer/1071817754</link>
<guid>https://www.zhihu.com/question/289814107/answer/1071817754</guid>
<content:encoded><![CDATA[
<p>近现代史尴尬名场面</p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic4.zhimg.com/v2-d321ae17fb8168b5735de6a42f63ce67_1440w.jpg" /></figure><p></p>
]]></content:encoded>
<pubDate>Fri, 10 May 2024 05:34:13 GMT</pubDate>
</item>
<item>
<title>李博杰赞同了回答: 如果有人自称中央特派员，手持中央密令，到看守所要求提走一个犯人，看守所会交人吗？</title>
<link>https://www.zhihu.com/question/654259075/answer/3480557855</link>
<guid>https://www.zhihu.com/question/654259075/answer/3480557855</guid>
<content:encoded><![CDATA[
<div> 提审出所 医疗释放 羁押改造 法律文书 密令<br />
<br />
提审出所后，可根据情况医疗释放或转移到其他羁押场所，每种情况都需要相应的法律文书，但并不存在所谓的密令。已被提审出所的人员正在接受改造，这些情况在知乎爽文中被讨论，不必深信其中信息。 <div>
<p>这事有人干过了。</p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic3.zhimg.com/v2-ad3f8e3022f482073c77b1b76b836af2_1440w.jpg" /></figure><p>来看看具体咋操作的。</p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic1.zhimg.com/v2-abc72c1137df99ea89d82317a1c19bac_1440w.jpg" /></figure><p>你看看，这事闹的。后面这些人别担心，都进去了，现在正在接受改造呢。</p><p>知乎爽文看看就得了，别当真。</p><p>从看守所提人出来，大概是以下状况:</p><ol><li>提审</li><li>出所就医</li><li>释放</li><li>换个羁押场所</li></ol><p>每种情况都有相应的法律文书。</p><p>但都没有这个密令。</p>
]]></content:encoded>
<pubDate>Fri, 10 May 2024 01:13:24 GMT</pubDate>
</item>
<item>
<title>李博杰赞同了文章: 网传Ilya Sutskever的推荐清单火了，掌握当前AI 90%</title>
<link>https://zhuanlan.zhihu.com/p/696834182</link>
<guid>https://zhuanlan.zhihu.com/p/696834182</guid>
<content:encoded><![CDATA[
<div> transformer、循环神经网络、LSTM、复杂度、推荐清单
<br />
总结:<br />
本文介绍了一份由OpenAI联合创始人Ilya Sutskever整理的机器学习研究文章清单。推荐清单涵盖了重点关注的技术主题，包括transformer架构、循环神经网络、LSTM等。推荐内容包括经典论文、博客文章和学术研究成果，旨在帮助行业从业者和科研人员了解AI领域的最新发展和必要知识。推荐清单涵盖了著名研究者的作品、重要论文以及相关课程，以及与算法统计和复杂度相关的内容。这些推荐内容涵盖了当前人工智能领域90%的重要内容，对于想要深入学习机器学习领域的读者具有重要参考价值。 <div>
<p>机器之心报道，<b>编辑：小舟。</b></p><p>随着生成式 AI 模型掀起新一轮 AI 浪潮，越来越多的行业迎来技术变革。许多行业从业者、基础科学研究者需要快速了解 AI 领域发展现状、掌握必要的基础知识。</p><p>如果有一份「机器学习精炼秘笈」，你认为应该涵盖哪些知识？</p><p>近日，一份网传 OpenAI 联合创始人兼首席科学家 Ilya Sutskever 整理的一份机器学习研究文章清单火了。网友称「Ilya 认为掌握了这些内容，你就了解了当前（人工智能领域） 90% 的重要内容。」</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic1.zhimg.com/v2-6a25bf2a973a551d928e4aec0a53f250_1440w.jpg" /></figure><p>推荐清单：<a class=" external" href="https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">arc.net/folder/D0472A20</span><span class="invisible">-9C20-4D3F-B145-D2865C0A9FEE</span><span class="ellipsis"></span></a></p><p>从研究主题上看，Ilya Sutskever 重点关注 transformer 架构、循环神经网络（RNN）、长短期记忆网络（LSTM）、神经网络的复杂度等。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic1.zhimg.com/v2-ca328500ebae6db26da270a3e63f32a4_1440w.jpg" /></figure><p><i>推荐清单部分截图。</i></p><p>例如，Ilya 推荐谷歌在 2017 年发表的经典论文《Attention Is All You Need》，这是 transformer 架构的问世之作。transformer 架构今天已经成为人工智能领域的主流基础架构，特别是它是生成式 AI 模型的核心架构。</p><p>Ilya 不仅推荐原论文，还推荐一篇由康奈尔大学副教授 Alexander Rush 等研究者在 2018 年撰写的博客文章 ——《The Annotated Transformer》。这篇文章以逐行实现的形式呈现了论文的注释版本，它重新排序梳理了原论文的内容，并删除了一些部分，最终展现的是一个完全可用的实现。2022 年 Austin Huang 等研究者又在其基础上编辑整理出一份采用 PyTorch 实现的更新版博客。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic4.zhimg.com/v2-de6c6d098c898cd5f3414243b8ff0163_1440w.jpg" /></figure><p>在 RNN 方面，Ilya 首先推荐阅读 AI 大牛 Andrej Karpathy2015 年撰写的一篇博客，强调「RNN 惊人的有效性」。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic2.zhimg.com/v2-61db19bd93a2defc0def1af993e9a811_1440w.jpg" /></figure><p>Ilya 还推荐了由纽约大学 Wojciech Zaremba（OpenAI创始团队成员）和 Ilya Sutskever 本人 2015 年发表的论文《Recurrent Neural Network Regularization》。当时，Ilya 还是谷歌大脑的研究科学家。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic3.zhimg.com/v2-ec925ddf7f005b4c3cac62b0d68b9492_1440w.jpg" /></figure><p>这篇论文为 RNN 提出了一种简单的正则化技术，阐述了如何正确地将 dropout 应用于 LSTM，大大减少了各种任务的过拟合，包括语言建模、语音识别、图像字幕生成、机器翻译等等。</p><p>此外，Ilya 还推荐了 DeepMind、伦敦大学学院 2018 年联合发表的论文《Relational recurrent neural networks》。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic3.zhimg.com/v2-7d7a8799a5d7231f6584c30dafa43026_1440w.jpg" /></figure><p>在 LSTM 方面，Ilya 推荐了 Anthropic 联合创始人、前 OpenAI 可解释性团队技术负责人 Christopher Olah 2015 年撰写的博客文章《Understanding LSTM Networks》，这篇文章全面细致地讲解了 LSTM 的基本知识，并阐明 RNN 取得的显著成果本质上是依靠 LSTM 实现的。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic2.zhimg.com/v2-8c93d45a245b5edcb09959dde797f755_1440w.jpg" /></figure><p>在「复杂度」方面，Ilya 重点推荐了《Kolmogorov Complexity and Algorithmic Randomness》一书中讲解「算法统计」的部分。柯尔莫哥洛夫复杂度为计算理论提供了一个用于探索问题固有复杂度的框架，可帮助研究人员更好地设计和评估 AI 模型。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic1.zhimg.com/v2-bb66425d54d39d76d3f6d77ceedb005c_1440w.jpg" /></figure><p>在这份推荐清单中，我们还看到了一些著名 AI 学者的经典论文。例如，2012 年 ImageNet 图像识别大赛中图灵奖得主 Geoffrey Hinton 组的论文《ImageNet Classification with Deep Convolutional Neural Networks》，这篇论文提出了 AlexNet，引入了全新的深层结构和 dropout 方法，颠覆了图像识别领域，甚至被认为开启了深度学习革命。Ilya 也是这篇论文的三位作者之一。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic1.zhimg.com/v2-7b8d1dbfd5328494e9e69a3798ecd140_1440w.jpg" /></figure><p>还有 2014 年，DeepMind Alex Graves 等人提出的神经图灵机（NTM）。NTM 将神经网络的模糊模式匹配能力与可编程计算机的算法能力相结合，具有 LSTM 网络控制器的 NTM 可以从输入和输出示例中推断出简单的算法，例如复制，排序等。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic2.zhimg.com/v2-b07b482242cede996d1f5680cb132269_1440w.jpg" /></figure><p>此外，Ilya 还推荐了神经网络应用于基础科学（化学）的研究论文、扩展定律相关文章等等，并推荐了斯坦福大学计算机科学课程 CS231n：用于视觉识别的卷积神经网络。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic2.zhimg.com/v2-7125f4072ba68897e332510cf874b0dd_1440w.jpg" /></figure><p>感兴趣的读者可以查看原推荐清单，了解更多内容。</p><p><i>参考链接：<a class=" external" href="https://twitter.com/keshavchan/status/1787861946173186062" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">twitter.com/keshavchan/</span><span class="invisible">status/1787861946173186062</span><span class="ellipsis"></span></a></i></p>
]]></content:encoded>
<pubDate>Fri, 10 May 2024 01:01:05 GMT</pubDate>
</item>
<item>
<title>李博杰发布了想法: <a href="https://mp.weixin.qq.com/s/ChbwjrKRWeU2Gdo_qiyVJA"></title>
<link>https://www.zhihu.com/pin/1771659377529049088</link>
<guid>https://www.zhihu.com/pin/1771659377529049088</guid>
<content:encoded><![CDATA[
<div> Chatbot Arena, SimilarWeb, 访问量, AI应用, 渗透率 
<br />
<br />
总结: SimilarWeb数据显示，Chatbot Arena在4月访问量达到4M，全球接近top 100，国内甚至可达第7，超过豆包。AI应用访问量普遍偏低，中科大评课社区访问量在选课季有0.6M，可排国内top 35。AI应用渗透率仍较低，LA和湾区人熟知ChatGPT，但大多数北京人对AI应用不甚了解，除了在五道口周围。华为AI相机在SimilarWeb排名全球top 10。 <div>
<p><a class="internal" href="https://mp.weixin.qq.com/s/ChbwjrKRWeU2Gdo_qiyVJA">https://mp.weixin.qq.com/s/ChbwjrKRWeU2Gdo_qiyVJA</a><br />这个榜单的数据来源是SimilarWeb。Chatbot Arena作为一个学术项目，4月的访问量也有4M，全球也接近top 100了，按照国内榜甚至能达到第7，甚至超过了豆包。当然SimilarWeb只能统计浏览器访问，不能统计App访问，所以对主要流量来源是App的不公平。<br />我做的中科大一个学校的评课社区，选课季（2024.1）SimilarWeb统计的访问量都有0.6M，放到这个国内AI榜上都top 35了，这么看起来大多数AI应用的访问量真是少的可怜。按照SimilarWeb的算法，我在华为参与的AI相机访问量可以排到全球总榜的top 10。<br />AI应用的渗透率还是太低了，我在LA和湾区街头遇到的人基本都听说过ChatGPT，但在北京街头遇到的人大多数都没听说过任何AI应用（五道口不算，我在楼下吃饭的时候经常听到周围在讨论大模型）。</p>
]]></content:encoded>
<pubDate>Wed, 08 May 2024 13:55:27 GMT</pubDate>
</item>
<item>
<title>李博杰赞同了回答: 为什么大学里上课几乎没几个人听课?</title>
<link>https://www.zhihu.com/question/453139394/answer/3490955103</link>
<guid>https://www.zhihu.com/question/453139394/answer/3490955103</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、视频课程、OpenAI、大模型、免费资源

总结:<br /><br />本文介绍了人工智能领域的优质视频课程资源，包括来自知学堂等机构提供的免费课程，涵盖了大模型、ChatGPT、NLP等相关内容。这些课程由业内专家如Andrej Karpathy、吴恩达、哈佛大学等提供，内容丰富实用，可帮助学习者快速入门人工智能知识。其中还推荐了一些高质量的机器学习和编程工具课程，如GitHub Copilot。通过这些免费资源学习，可以提升编程水平和理解AI技术，为未来工作和学习提供重要帮助。 <div>
<p>就拿计算机学院来说吧，基本上都要讲点人工智能什么的，但是绝大多数还停留在这个是线性回归，这个是决策树等等。</p><p>这些内容你要说没用吧，那也不是；但是这种基础的东西讲的好的多了去了。</p><p>但是比较新的内容，比如说大语言模型LLM，能讲的好的一般都不在学校，而在学校里面讲这个的，大多数只能讲个皮毛。</p><p>但是，人总是需要看优质内容的，所以大家只是从低质低效的课堂上课，转移到优质高效的线上看。</p><p>比如说从OpenAI离职的<span class="nolink">Andrej Karpathy</span>大神，两个小时的视频，教你从头开始，写一个GPT出来。</p><p>收获了450万的观看。</p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic4.zhimg.com/v2-02bc45a072a4b8aca4554bd53cccc7bf_1440w.jpg" /></figure><p>这是什么概念，可以说，在AI这种依然属于小众的领域，这种播放量极其恐怖。</p><p>但重要的，这类型优质的视频基本上都是免费的，可以随时看的，更更更重要的是，他还分享了完整的代码，你打开就能运行。</p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic2.zhimg.com/v2-447f0125384ebf08b2d4d6e937a80745_1440w.jpg" /></figure><p>直接就能运行，试问有几个老师的课件能准备到这种地步？</p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic4.zhimg.com/v2-be4cea5924caf302baee07bb2a4c4fff_1440w.jpg" /></figure><p>过去一年中，我看了很多的优质视频，这里给大家分享出来，基本上都是关于AI的。</p><p>特别是关于AI在工作以及学习中的使用，跟AI理论不同，它更加的需要跟具体的工作结合起来，比如用GPT来处理一大堆的文档，或者简单的用GPT来做数据分析，这都需要对GPT以及AI的适用范围有所了解。</p><p>这里我推荐一个知学堂开设的AI工具课程，0.1元的课程基本上可以掌握主流的AI工具，比如Kimi这样的多模态大模型，以及AI+Excel这样的特定领域大模型。</p><a></a><p>特别是出了课程之外，还会给你一些提示词工程方面的资料，基本上可以帮助你快速上手各种类型的大模型。</p><h3>ChatGPT 开发者提示工程</h3><p>课程简要介绍：由OpenAI和Coursera联合发布的课程，教授开发者如何使用大型语言模型（LLM）进行应用开发。</p><p>课程亮点：适合初学者，提供使用OpenAI API的实践经验。</p><p>链接：<a class=" wrap external" href="https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/" rel="nofollow noreferrer" target="_blank">ChatGPT Prompt Engineering for Developers</a></p><p><i>全是免费的，而且质量都非常高，甚至可以通过他们的平台免费玩ChatGPT的API。</i></p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic1.zhimg.com/v2-6db5d1b816d8332148dec3989569faf8_1440w.jpg" /></figure><p class="ztext-empty-paragraph"><br /></p><h3>0基础人工智能入门</h3><p>课程简要介绍：由吴恩达（Andrew Ng）提供的入门课程，涵盖人工智能的基本概念和原理。</p><p>课程亮点：适合零基础学习者，内容全面，易于理解。</p><p>链接：<a class=" wrap external" href="https://t.co/KaJw3MV5aD" rel="nofollow noreferrer" target="_blank">Coursera</a></p><p><i>其实是deeplearning.ai的课程放在了Coursera上了，只是想提一下Coursera上的免费课程非常的多</i></p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic1.zhimg.com/v2-f734181aa15e552bea8b0a21a54b7860_1440w.jpg" /></figure><h3>Python人工智能入门</h3><p>课程简要介绍：哈佛大学的CS50课程，涵盖计算机基础知识、强化学习、Python、算法等。</p><p>课程亮点：由David Malan教授主讲，教学风格风趣幽默。</p><p>链接：<a class=" wrap external" href="https://www.edx.org/course/cs50s-introduction-to-artificial-intelligence-with-python" rel="nofollow noreferrer" target="_blank">HarvardX: CS50's Introduction to Artificial Intelligence with Python</a></p><p><i>哈佛的神课，懂得都懂，不懂得去看看</i></p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic1.zhimg.com/v2-643bcd72e760ddd26c9ee1ccb50d1230_1440w.jpg" /></figure><p class="ztext-empty-paragraph"><br /></p><h3>NLP及其工作原理</h3><p>课程简要介绍：斯坦福大学提供的自然语言处理（NLP）课程，介绍最新的神经网络技术。</p><p>课程亮点：由斯坦福大学教授克里斯托弗·曼宁讲授，适合专业领域学习。</p><p>链接：<a class=" wrap external" href="https://online.stanford.edu/courses/cs224n-natural-language-processing-deep-learning" rel="nofollow noreferrer" target="_blank">Natural Language Processing with Deep Learning | Course | Stanford Online</a></p><p><i>算是LLM的基础，想要深入了解NLP的适合看看</i></p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic4.zhimg.com/v2-c782385d20f2031bbd8684a68812abf7_1440w.jpg" /></figure><h3>学习提示工程</h3><p>课程简要介绍：开源课程，为初学者提供提示工程（Prompt Engineering）的全面学习。</p><p>课程亮点：适合零基础者，内容分类明确，便于不同层次学习者选择。</p><p>链接：<a class=" external" href="https://learnprompting.org/" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">learnprompting.org/</span><span class="invisible"></span></a></p><p><i>它很多课程是付费的，你学这个最基础的就行，OpenAI员工做的</i></p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic1.zhimg.com/v2-e4a59097f7544a42eff2dce2f2b06cb4_1440w.jpg" /></figure><h3>机器学习教育</h3><p>课程简要介绍：谷歌提供的机器学习课程，包括基础和高级课程，涵盖机器学习的基础知识和核心概念。</p><p>课程亮点：提供机器学习速成课程（MLCC），适合快速学习。</p><p>链接：<a class=" external" href="https://developers.google.com/machine-learning" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">developers.google.com/m</span><span class="invisible">achine-learning</span><span class="ellipsis"></span></a></p><p><i>Google出品的课程，质量就不用说了。</i></p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic4.zhimg.com/v2-76ff89229655223d02bd7f12403f1a0f_1440w.jpg" /></figure><h3>GitHub Copilot</h3><p>课程简要介绍：微软提供的在线课程，帮助开发者掌握GitHub Copilot的使用方法和最佳实践。</p><p>课程亮点：提升编程水平和创造力，节省学习时间和成本。</p><p>链接：<a class=" external" href="https://github.com/features/copilot" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">github.com/features/cop</span><span class="invisible">ilot</span><span class="ellipsis"></span></a></p><p><i>AI编程辅助工具，不过最近发现了FittenCode这个工具，效果会更好一些</i><br /></p><h3>李宏毅教授</h3><p>课程简要介绍：免费分享的各种关于AI的视频</p><p>课程亮点：紧跟时事，通俗易懂，科普性质</p><p>链接：自己找</p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic3.zhimg.com/v2-ef0fd99e3036b6a41a3a83f4e76ddc52_1440w.jpg" /></figure><h3>Andrej Karpathy</h3><p>课程简要介绍：OpenAI出来的非常懂技术的员工</p><p>课程亮点：非常硬核的AI知识，特别是GPT方面</p><p>链接：自己找</p><p class="ztext-empty-paragraph"><br /></p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic1.zhimg.com/v2-56b326ee2841d31d5299d04f9d510058_1440w.jpg" /></figure><p></p>
]]></content:encoded>
<pubDate>Wed, 08 May 2024 09:35:15 GMT</pubDate>
</item>
<item>
<title>李博杰赞同了文章: NSDI 2024 速读几篇</title>
<link>https://zhuanlan.zhihu.com/p/695575620</link>
<guid>https://zhuanlan.zhihu.com/p/695575620</guid>
<content:encoded><![CDATA[
<div> 缓存淘汰算法, 多副本KV存储, 云资源管理调度, 微服务资源调度, 负载均衡<br />Autothrottle提出了一种在微服务架构中优化资源管理的方法，通过动态调整CPU分配以满足SLA，降低延迟，提高资源利用。LoLKV是基于RDMA的Logless线性化KV存储系统，通过减少apply动作提高性能。Prequal是一种基于请求响应时间和活跃请求数的负载均衡器，能减少延迟和提高资源利用。SIEVE提出了一种简单高效的缓存淘汰算法，满足lazy promotion和quick demotion特性。Can't Be Late介绍了如何在有明确deadlines任务处理中优化spot instance的运行以降低成本。Load is not what you should balance引入了Prequal负载均衡器，通过主动探测服务器负载，选择响应时间和活跃请求数低的服务器，以实现负载均衡和降低延迟。<br /><br />总结: 这些文章分别探讨了缓存淘汰算法、KV存储、云资源调度、微服务资源调度和负载均衡等领域的创新技术方案，以提高系统性能、降低延迟、优化资源利用和完成具有deadline的任务。而这些解决方案主要通过提出新型算法或策略，结合实时请求需求和服务器状态数据，以实现更高效的系统运行和服务质量保障。 <div>
<p>看几篇NSDI-2024，Topic如下：<br /></p><ul><li>（1）Cache：如何设计简单高效的缓存淘汰算法，并且满足lazy promotion (惰性升级)和quick demotion (快速降级)特性</li><li>（2）KV storage：多副本Logless、Linearizable强一致kv storage</li><li>（3）云资源管理调度：利用spot instance处理有明确deadlines任务，动态调度spot instance和on-demand的使用，保证任务都如期完成，且花的钱更小</li><li>（4）微服务资源调度：现在微服务架构下，一个应用通常上下游会设计非常异构的微服务，如果给这些微服务动态的分配资源，实现满足SLA的情况下，减少资源使用</li><li>（5）负载均衡：面对异构和动态的负载变化，Google提出了Prequal（Probing to Reduce Queuing and Latency）这一新型负载均衡器，通过主动探测服务器负载，依据估计的请求响应时间和活跃request-in-flight（RIF）数进行服务器选择，以最小化实时请求延迟</li></ul><h2><br /><br />1. SIEVE is Simpler than LRU: an Efficient Turn-Key Eviction Algorithm for Web Caches</h2><p><br /><b>Community Award Winner!</b><br /></p><ul><li>基本介绍：</li></ul><p>缓存热数据访问，一般是符合power-law distribution，也就是通常所说的二八原则。所以一个好的缓存更新淘汰算法，应该它具备两个重要的特性：<br /></p><ul><li>（1）lazy promotion (惰性升级)：<br />缓存的惰性首先体现通常只有访问的数据才会进入缓存，一般不会提前将数据加载到缓存；其次就是惰性升级，约束，在缓存第一次访问的时候，不会将其低级缓存推送到高级缓存，只有频繁访问或者预期将被重新访问，才会被提升到一个更高级别的缓存。这样可以保证热数据尽快进入缓存，真正的热数据可以进入高级的缓存，不会被快速淘汰，低级缓存不会快速进入高级缓存而可以快速被淘汰，进而使得留在缓存中的数据尽可能是真正的热数据。<br /></li><li>（2）quick demotion (快速降级) ：<br />减少那些可能不会再被访问的数据对缓存的占用，提升缓存的效率。也就是偶尔被访问的非真正热点数据即使进入了缓存，也能快速的被淘汰出来，把空间留给真正的热数据。<br /><br /><br /></li><li>解决方案：</li><ul><li>基于上面两个特性，再来看SIEVE缓存更新淘汰算法（如下图）</li></ul></ul><p class="ztext-empty-paragraph"><br /></p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic4.zhimg.com/v2-0a66130cd717c3a73e410be7475f1663_1440w.jpg" /></figure><p class="ztext-empty-paragraph"><br /></p><ul><ul><li>Cache miss：</li><ul><li>当访问对象不在缓存中，那么插入对头，x.visited设置为0（惰性）</li></ul><li>Cache hit：</li><ul><li>当访问对象在缓存中，x.visited设置为1（惰性升级，只有缓存再次被访问时，才升级为更高级的缓存，避免其被快速淘汰换出）</li></ul><li>Cache full：eviction</li><ul><li>如何缓存空间满了，那么从尾到头找，x.visited == 0的淘汰（快速降级），如果x.visited = 1，那么设置为x.visited = 0（快速降级，升级后的缓存如何降级）</li><li>并记录下这个位置淘汰位置的下一个位置为hand，下次淘汰从hand开始找，整个淘汰，就是从尾扫到头，再从尾扫到头</li><li>所以一个升级后的缓存x.visited = 1，经过一次淘汰扫描变成x.visited = 0，那么这个缓存扫一轮之后，这个还没有被访问到才会被eviction<br /><br /></li></ul></ul><li>观察总结</li><ul><li>优点：惰性升级和快速降级特性都表现良好，可以很好的缓存热数据，并适应全表扫描等场景</li><li>缺点：淘汰性能有一定的不确定性，可能会造成延迟上会有长尾</li></ul></ul><h2><br /><br />2. LoLKV: The Logless, Linearizable, RDMA-based Key-Value Storage System<br /></h2><ul><li>基本介绍：</li></ul><figure><img class="origin_image zh-lightbox-thumb" src="https://pic1.zhimg.com/v2-377c4bed79d210d12ed5c094e8b94864_1440w.jpg" /></figure><p><br />利用rdma做多副本k-v数据一致性复制，传统的复制状态机模型，例如raft，Leader提供读写和复制，先让log达成一致性，然后apply到k-v存储中。LoLKV 还是Leader提供读写和复制（如上图），但是支持所谓的logless，就是数据先写Segment store（其实本质就是log），然后更新 hash table索引（相当于apply），数据就可见了。相当于减少了apply的写入放大。<br /></p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic2.zhimg.com/v2-11c9932e9a9972d9ce12ca2757fd07f1_1440w.jpg" /></figure><figure><img class="origin_image zh-lightbox-thumb" src="https://pic2.zhimg.com/v2-5dbff68d375b545550fef3427a2acdf1_1440w.jpg" /></figure><p><br /><br />但是代价就是Segment store需要定期做compaction，这里会有一些放大。类似阿里云的EBS（如上图），写底层Pangu append only replicated DataFile（实际就是log，只是这里是存算分离架构），然后更新内存和Meta，数据就可见了。当然log本身是包含了meta的，如Figure 5，所以故障重启恢复就会在内存中恢复相关的Meta。<br /><br /></p><ul><li>观察总结：</li><ul><li>这里logless本质是 log as data，logless是减少了apply动作，但是随着频繁的写入，后台log就需要compaction</li><li>只能支持随机读写场景的k-v store，不利于scan操作，因为不能对key进行排序了，kv数据放在log中是无序的</li></ul></ul><p class="ztext-empty-paragraph"><br /></p><h2><br /><br />3. Can't Be Late: Optimizing Spot Instance Savings under Deadlines<br /></h2><p><b>Awarded Outstanding Paper!</b><br /></p><ul><li>基本介绍：</li></ul><p>这篇是介绍优化公有云spot instance在有明确 deadlines 任务处理的场景，我们知道公有云spot instance价格很便宜，很多时候都是1~2折，但是，spot instance并不保证能够持续提供服务，一旦资源紧张，云上会回收相关 spot instance，所以对于有明确deadlines的jobs来说，光使用 spot instance肯定是无法保证一定可以在deadline时间内完成，所以需要配合on-demand instance（按需实例，价格比较贵）。那么如何调度spot instance和on-demand的使用，才能保证任务都如期完成，且花的钱更小呢 ？<br /></p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic4.zhimg.com/v2-b33391475a1bb1bfcd3b7986d8dd8d0b_1440w.jpg" /></figure><p class="ztext-empty-paragraph"><br /></p><ul><li>Spot instance的特点</li><ul><li>Spot instance的供应变动很大，而且基本没啥规划</li><li>Spot instance价格比较稳定，而且比on-demand instance便宜很多<br /></li></ul><li>解决方案：贪心的策略</li><ul><li>C(t)：代表t时刻，任务剩余计算时间</li><li>R(t)：代表t时刻，任务到截止时间的剩余时间</li><li>d：代表job在spot或者on-demand切换需要的时间</li><li>Greedy policy：</li><ul><li>job在 spot instance上跑直到其被抢占，如果没有其他spot instance可用，则进入idle等待，直到有 spot instance，就继续用 spot instance处理</li><li>如果R(t)&lt;C(t)+2d，而job处于idle，则使用on-demand实例进行处理（假设on-demand实例资源是足够的）</li></ul></ul><li>观察总结：</li><ul><li>方法其实比较简单和朴素，扩展k8s scheduler，实现起来也不复杂，可以做云内、云外资源、spot intance、on-demand混合云调度，但是实际应用有一些地方需要注意：</li><ul><li>有一些job执行它是没法保证中间结果的，意味着执行期间被抢占，那么意味着需要重做，也就是C(t)需要维持原来的值，那么R(t)&lt;C(t)+2d这个界可能会有一些问题，R(t)&lt;2*C(t)+d可能会比较靠谱</li><li>还有一些job是有依赖关系的，这种C(t)的计算会更加复杂，需要根据DAG依赖关系进行计算</li></ul></ul></ul><h2><br /><br /><br />4. Autothrottle: A Practical Bi-Level Approach to Resource Management for SLO-Targeted Microservices<br /></h2><p><b>Awarded Outstanding Paper!</b><br /></p><ul><li>基本介绍：</li></ul><p>现在微服务架构下，一个应用通常上下游会设计非常异构的微服务，如何配置这些微服务容器的资源来保证应用端到端的延迟满足用户SLA是非常难得，配置过多的资源，会造成浪费，配置太小，会造成延迟变大，影响用户SLA。这么多微服务，如果去配置他们资源，保证服务SLA同时减少资源浪费呢 ？<br /></p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic2.zhimg.com/v2-3491b4ab05f086b631d03d1fb8cb42d1_1440w.jpg" /></figure><p><br /><br /><br /></p><ul><li>解决方案：<br /></li><ul><li>CPU allocations和latency的关系 ？</li><ul><li>首先我们需要一个更好的指标来评估Pod cpu资源分配和latency之间的关系，相比cpu利用率，Autothrottle认为cpu throttle count会更加合适。</li><li>Why cpu throttle count？：这里首先解释下什么是cpu throttle count，Linux内核使用CFS公平调度（本质调度的是进程，这里简单起见，直接描述为容器），一个容器，通常会值资源request和limit，例如cpu request=1c limit=2c，Linux cfs调度其保证了在一个调度周期内每个容器分配到资源是按照其request公平分配，如果在调度周期内存使用cpu超过limit，那么就会出现throttle，直到下一个调度周期，这个容器才能继续按照request来公平的分得cpu，那么显然，cpu throttle出现其实本质就意味着延迟，这个指标相比cpu利用率，更加明确的。<br /></li></ul></ul><li>Service-level：</li><ul><li>快速轻量级的Captains组件完成监控每个微服务的cpu throttle ratio，如果大于目标值，那么增加cpu quota，也就是limit，相反则减小cpu quota（这个直接通过修改机器上cgroup即可实现）。Captains本地部署，可以快速的根据实际的负载做出s级的响应；避免cpu throttle，造成延迟抖动。<br /></li></ul></ul><figure><img class="origin_image zh-lightbox-thumb" src="https://pic2.zhimg.com/v2-28be51fc104062b733d82970cd8f8c51_1440w.jpg" /></figure><p class="ztext-empty-paragraph"><br /></p><ul><li>Application-level</li><ul><li>通过全局拿到的rps、cpu利用率、throttle、延迟等数据，会周期的计算一个cpu throttle target告诉Captains，Captains后续会在这个cpu throttle target的基础上做调整</li></ul></ul><p class="ztext-empty-paragraph"><br /></p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic3.zhimg.com/v2-fde1b6f963ad41cf022a1f771a5cd432_1440w.jpg" /></figure><p class="ztext-empty-paragraph"><br /></p><ul><li>观察总结：</li><ul><li>cpu throttle确实是一个更好的关注延迟的指标，而且不用侵入理解业务系统；此外本地部署Captains可以快速的秒级调整Quota上限，也就是垂直扩缩容，足够兼容且及时，确实是一个不错的方法</li><li>但是节点垂直扩缩容弹性比较有限的，毕竟受限物理节点的资源上限，而且垂直扩缩容的弹性留得越多，那么意味着资源浪费也就越严重，作为本地机动机制是没有问题，可以解决一些长尾问题。但是要整体节省资源，核心还是要在全局上规划资源分配。但是在线服务不比serverless或者离线，很难随时做水平或者垂直的调整，过量分配感觉在所难免，所以整体优化现在还是走混部，既然在线不能动，那就动离线，在线忙，离线出走，在线闲，离线进来。所以现在在线核心服务的处理逻辑都很简单，sla不够，就拍脑袋扩容，扩容到不影响sla为止 :(</li></ul></ul><p class="ztext-empty-paragraph"><br /></p><h2><br /><br />5. Load is not what you should balance: Introducing Prequal</h2><ul><li>基本介绍</li><ul><li>这篇介绍了Google解决分布式多租户系统中的负载均衡问题，特别是对于YouTube这样的大规模云服务。传统方案，负载均衡策略如动态加权轮询（WRR）侧重于平衡分布式服务器间的CPU利用率，以确保资源的有效利用和响应时间的降低。但是在异构和non-uniform、time-varying antagonist load背景下，仅关注CPU负载平衡可能会导致长尾延迟、错误率及资源使用效率的问题。因此，论文提出了Prequal（Probing to Reduce Queuing and Latency）这一新型负载均衡器，旨在通过主动探测服务器负载，依据估计的请求响应时间和活跃request-in-flight（RIF）进行服务器选择，以最小化实时请求延迟<br /><br /></li></ul><li>关键问题：</li><ul><li>每台机器运行着不同的程序组合，并伴随着一些离线任务，机器的可用资源在持续动态地变化着，机器配置不同，网络延时不同，传统round robin和随机的复杂均衡策略其实是无法很好工作的[1]。</li><li>即使WRR根据下游的cpu占用率来进行分流，但明显地它解决不了延时相关的问题，甚至cpu的问题也解决不了：因为它被实现为定期reload一个权值列表，可想而知更新频率高不了，等到负载均衡反应过来，一大堆请求可能都超时了。并且这儿有个数学问题：怎么把cpu占用率转为权值。假设下游差异仅仅由同机运行的其他程序导致，机器配置和网络完全相同，两台机器权值之比是cpu idle之比吗？假如是的，当我们以这个比例给两台机器分流之后，它们的cpu idle应该会更接近对吧？而这会导致我们的分流比例也变得接近，从而使两台机器的cpu idle又出现差距。你注意到这个悖论了吗？这些因素使得这类算法的实际效果和那两个基本算法没什么差距，甚至更差，用者甚少[1]。<br /></li></ul><li>核心理念</li><ul><li>Prequal挑战了仅关注CPU负载的传统观念，转而根据预期的服务质量和系统状态动态调整负载分配策略，实现感知下游负载、规避慢节点来实现负载均衡</li></ul><li>核心方法：</li><ul><li>基于<b>估计延迟</b>与<b>活跃在飞请求RIF数</b>做服务器选择：</li><ul><li>不同于单纯基于CPU利用率的负载均衡，Prequal选择服务器时考虑两个关键指标：估计的请求响应时间和活跃在飞请求RIF。这一选择标准旨在直接反映用户感知的延迟，并能够适应服务器间性能差异和瞬时负载波动</li><li>服务器会存储最近一段时间内完成的查询的响应时间，并记录当时的活跃在飞请求RIF，这样就可以根据活跃在飞请求RIF标签来估计延迟</li></ul><li>主动探测：</li><ul><li>通过主动探针机制来实时获取服务器的RIF及其相关的延迟数据</li><li>通过主动探测的数据和历史数据相结合的方式实现了近实时的负载估计</li></ul><li>扩展PodC（power of d choices）范式：</li><ul><li>服务器选择时候的抽样和选择过程融入了延迟和RIF信息，更具针对性，过程大致如下：会从d个候选服务器中，先根据服务器RIF分布来确定属于hot还是cold，分位值QRIF一般设置在0.6~0.9这个区间，大于这个值，服务器标记为hot，小于这个值标记为cold，如果全部服务器为hot，那么选择RIF最小的，否则，选择cold预估延迟最小的服务器<br /><br /></li></ul></ul><li>观察总结：</li><ul><li>好处：</li><ul><li>降低延迟：通过选择具有最小延迟的副本，Prequal可以确保请求得到快速响应，从而提高用户体验</li><li>高效资源利用：通过考虑RIF（请求中的数量），Prequal能够平衡负载，避免某些副本过载而其他副本空闲，从而提高服务器资源的利用率</li><li>适应性：Prequal的HCL规则可以根据当前的负载情况动态调整，选择最合适的副本，这使得系统能够适应不断变化的负载模式。</li><li>避免过载：通过PodC（power of d choices）可以避免将请求发送到RIF过高的副本</li></ul><li>其他讨论：</li><ul><li>PodC（power of d choices）实践有Two Random Choices，应用于负载均衡有一定的效果，更多讨论参见[1]</li><li>关于引入inflight request相关统计优化的还有brpc，他们在使用的locality-aware load balancing（也是一种自适应下游负载、规避慢节点的通用负载均衡算法，详细可参见[1]）引入了inflight delay追踪未结束的RPC，应对超时或者其他错误场景，因为这种场景返回可能会很慢（超时一般会是正常延时的若干倍），在这段时间内可能做出了很多错误的分流</li><ul><li>未结束RPC的平均耗时inflight delay=“当前时间 - 发出时间之和 / 未结束次数”，当inflight delay大于平均延时时，可以线性地惩罚节点权值，即weight = base_weight * avg_latency / inflight_delay</li><li>locality-aware load balancing：假设只有两台下游节点，W代表权值，QPS代表吞吐，L代表延时，那么W1 = QPS1 / L1和W2 = QPS2 / L2分别是这两个节点的分流权值</li></ul></ul></ul></ul><p><br /><br /><br /><b>Notes:</b><br />限于作者水平，难免有理解和描述上有疏漏或者错误的地方，欢迎共同交流；部分参考文献已经在正文和参考文献中列表注明，但仍有可能有疏漏的地方，有任何侵权或者不明确的地方，欢迎指出，必定及时更正或者调整；文章供于学习交流，转载注明出处。<br /><br /><br /><b>参考</b><br />[1]. Locality-aware load balancing. <a class=" external" href="https://github.com/apache/brpc/blob/master/docs/cn/lalb.md" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">github.com/apache/brpc/</span><span class="invisible">blob/master/docs/cn/lalb.md</span><span class="ellipsis"></span></a><br />[2]. The Power of Two Random Choices. <a class="internal" href="https://zhuanlan.zhihu.com/p/64538762"><span class="invisible">https://</span><span class="visible">zhuanlan.zhihu.com/p/64</span><span class="invisible">538762</span><span class="ellipsis"></span></a><br />[3]. Zhang, Yazhuo, et al. "Sieve is simpler than lru: an efficient turn-key eviction algorithm for web caches." 21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24). USENIX Association. 2024.<br />[4]. Alquraan, Ahmed, et al. "{LoLKV}: The Logless, Linearizable,{RDMA-based}{Key-Value} Storage System." 21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24). 2024.<br />[5]. Wu Z, Chiang W L, Mao Z, et al. Can't Be Late: Optimizing Spot Instance Savings under Deadlines[C]//21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24). 2024: 185-203.<br />[6]. Wang Z, Li P, Liang C J M, et al. Autothrottle: A Practical Bi-Level Approach to Resource Management for SLO-Targeted Microservices[J]. arXiv preprint arXiv:2212.12180, 2022.<br />[7]. Wydrowski B, Kleinberg R, Rumble S M, et al. Load is not what you should balance: Introducing Prequal[J]. arXiv preprint arXiv:2312.10172, 2023.<br />[8]. Zhang W, Xu E, Wang Q, et al. What's the Story in {EBS} Glory: Evolutions and Lessons in Building Cloud Block Store[C]//22nd USENIX Conference on File and Storage Technologies (FAST 24). 2024: 277-291.</p>
]]></content:encoded>
<pubDate>Wed, 08 May 2024 00:34:34 GMT</pubDate>
</item>
<item>
<title>李博杰赞同了回答: 在动车站停车停了大半年，停车费大几千，有没有办法少付一些钱?</title>
<link>https://www.zhihu.com/question/549391632/answer/2936555013</link>
<guid>https://www.zhihu.com/question/549391632/answer/2936555013</guid>
<content:encoded><![CDATA[
<p>我是做停车场设备和运营的厂家的。</p><p>2000以下，耍点聪明跑了，停车场会认栽。</p><p>2000-5000，停车场都是重点关注的僵尸车，如果是我们厂家的设备，出场甚至会给管理方发送警示信息，你以后去其他我们设备的停车场（不说品牌了），随时可能拦住你让你补交。如果你再次回到这个停车场，我们会发送警示信息给管理者，让管理者找你。</p><p>5000以上我们不怎么管，因为管理方一般会直接起诉，可以判刑的。</p><p>如果你的诉求只是少交点。和管理方协商，以月租的价格缴清，大部分管理方会同意。</p><p>如果还想再少点，除非你有正当的理由（比如不可抗力因素等），几乎不可能。</p><p>另外有两种情况，你欠了5000以上走了，管理方没法找你。</p><p>一种是你车被砸了被划了被破坏了，相当于停车的权益受到了侵害，和停车场变成了受害者的关系，停车场可能息事宁人，不收费。</p><p>第二种是…嗯，自己做停车场运营的，不说了。</p><p class="ztext-empty-paragraph"><br /></p><h2>我看了下挺多猜测和办法的，我不可能说行业的漏洞规则的。但是确实有办法，而且是合法合理合规的，希望大家不要往违规的小聪明方向猜测。不要做违法违规的事情，因小失大不划算。</h2>
]]></content:encoded>
<pubDate>Tue, 07 May 2024 15:44:52 GMT</pubDate>
</item>
<item>
<title>李博杰赞同了回答: 如何看待 USENIX ATC 2024 审稿意见？</title>
<link>https://www.zhihu.com/question/653360753/answer/3490743978</link>
<guid>https://www.zhihu.com/question/653360753/answer/3490743978</guid>
<content:encoded><![CDATA[
<p>Rebuttal 前OveMer 2424（RevExp 3234），Rebuttal 时力挽狂澜，消除了 reviewers 的所有 concerns，2 个 2 分都改成了 3 分，最终 OveMer 3434，接收！✌️</p><p>祝贺来自新加坡国立的实习生高彬和来自上交的实习生卓旻！ </p><p>我们论文提出 CachedAttention，通过高效率地缓存和复用 LLM 历史对话中产生的KV Cache， 提升了LLM 推理过程中 8 倍+的 Prefilling 吞吐量，降低了 50%+的端到端推理成本！ 该技术已经落入华为云服务产品版本中，预计在 6 月份的华为开发者大会 HDC 上发布，欢迎大家关注！</p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic4.zhimg.com/v2-c0a4f3732300785e75d5c2f51c1c8bcb_1440w.jpg" /></figure><p>论文简介如下：</p><figure><img class="origin_image zh-lightbox-thumb lazy" src="https://pic3.zhimg.com/v2-8045b6ae34210a08834dfcd4ec6f876e_1440w.jpg" /></figure><p>PS：持续招聘实习生，有竞赛经验或顶会论文的学生优先，欢迎来一起解决工业界的真实技术难题！</p>
]]></content:encoded>
<pubDate>Tue, 07 May 2024 15:35:27 GMT</pubDate>
</item>
<item>
<title>李博杰关注了问题: 美团单车为什么取消了机械锁，改用app锁车？</title>
<link>https://www.zhihu.com/question/476136480</link>
<guid>https://www.zhihu.com/question/476136480</guid>
<content:encoded><![CDATA[
<p>现在骑行结束要在app里点击锁车才行，要是没信号怎么办，为什么会有这样的设定</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic1.zhimg.com/v2-7a5baea28ef4144a67f3fe7428cf562e_1440w.jpg" /></figure><p></p>
]]></content:encoded>
<pubDate>Tue, 07 May 2024 05:32:28 GMT</pubDate>
</item>
<item>
<title>李博杰关注了问题: 给你111111人民币，但是你必须从以下10种惩罚中选择4种，你选择哪4个？</title>
<link>https://www.zhihu.com/question/655057941</link>
<guid>https://www.zhihu.com/question/655057941</guid>
<content:encoded><![CDATA[
<p>A.穿任意2次元角色cos服持续10小时.</p><p>B.不准喝任何饮品的情况下，吃下2根辣椒、1g阿斯巴甜、10g柠檬酸。</p><p>C.修改自己在所有社交平台上的ID与密码，和原来不同即可。</p><p>D.在纸上抄圆周率前10000位，不能有错。</p><p>E.跑114.514m，所用时间不得超过15s，如果挑战失败可以选择其他项目。</p><p>F.在一小时内创造记号挑战TREE(3)，如果挑战失败可以选择其他项目。</p><p>G.坐火车，总时长200小时，不需要自己出钱买票。</p><p>H.列竖式计算十个随机的random()乘法。</p><p>I.在奖金中扣除33333块钱的个人所得税。</p><p>J.完成16次MBTI人格问卷，并使16次结果各不相同。</p><p>加点描述：random()指0到1之间随机的double类型数</p>
]]></content:encoded>
<pubDate>Tue, 07 May 2024 05:04:22 GMT</pubDate>
</item>
<item>
<title>李博杰赞同了文章: 让 Altman 也玩上瘾的「语音 Twitter」，在硅谷彻底火了</title>
<link>https://zhuanlan.zhihu.com/p/696214160</link>
<guid>https://zhuanlan.zhihu.com/p/696214160</guid>
<content:encoded><![CDATA[
<blockquote>能不能成不好说，起码挺新鲜的。</blockquote><p>在后移动互联网时代，已经越来越难看到 App 在产品层面上的创新，Airchat 带来了一点新意。过去一段时间，这款仅限邀请注册的 App 在风险投资人、科技公司高管以及其他硅谷名人中流行了起来。</p><p>简言之，Airchat 可被视为 Twitter 的语音化版本，它重新定义了社交媒体上的互动方式。在这里，你可以像其他任何社交平台一样，关注你感兴趣的人、发布推文或者和网友交流。<b>不同之处在于，你发布的任何信息都必须通过语音的方式，用键盘打字在 Airchat 上是不被允许的。</b></p><p>正如 Airchat 官网的 Slogan 所说：「Just Talk.」</p><p>根据营销情报公司 Sensor Tower 的估计，自 4 月 12 日推出以来，Airchat 的下载量已超过 30,000 次。因为太受欢迎的缘故，Airchat 甚至在发布 4 天后就关闭了邀请通道。硅谷精英如 OpenAI CEO Sam Altman 也出现在 App 中，并且还对 Aitchat 进行了投资。</p><p>其实 Airchat 在去年就发布过一个版本，之后两位联合创始人布莱恩·诺加德（Brian Norgard）和纳瓦尔·拉维坎特（Naval Ravikant）带领团队重构了这个 App。</p><p>这两位创始人在硅谷都颇具影响力。</p><p>纳瓦尔是著名的投资人，曾投资过 Twitter、Uber、Notion、Stack Overflow 等众多独角兽企业，也是股权众筹平台 AngelList 的创始人。<b>在中国，他更为人熟知的身份是畅销书《纳瓦尔宝典》的原始作者</b>。诺加德就是 AngelList 的第一位投资人。在创办 Airchat 之前，他是约会软件 Tinder 的首席产品官。</p><p>那么，这款「语音版 Twitter」到底是因为什么，彻底风靡了硅谷的？</p><h2><b>01「Just Talk」</b></h2><p>从产品形态上看，Airchat 可以看作是 Twitter 和 Clubhouse 的结合——它首先是一个像 Twitter 一样的社交平台。但是像 Clubhouse 一样，Airchat 把音频的优先级放在了最高。</p><p>启动 App 之后，系统会首先提示你关注一些用户，之后你就会看到熟悉的瀑布流界面。组成这些瀑布流的是一个个文本块。<b>Airchat 没有发送文本的选项，这些文字实际上都是语音转录而来</b>。值得一提的是，Airchat 的语音转录识别程度相当高，得到了众多用户的称赞。中国台湾地区媒体提到，Airchat 甚至可以根据用户的口音判断，转录的文字使用简体还是繁体。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic3.zhimg.com/v2-970210ae3026f0156b355502bfdd7722_1440w.jpg" /><figcaption>Airchat 用户界面｜图片来源：TechCrunch</figcaption></figure><p>点击屏幕右下角的播放按钮，这些语音就会以 2 倍速播放。也就是说，<b>如果只是单纯消费内容的话，Airchat 两个选项：听和读。但是一旦你想发布内容或者和其他使用者交流时，唯一的方式就是发语音</b>。</p><p>纳瓦尔认为，语音是比文本更亲密的对话媒介——相比文字，语音可以传递情绪、语调等更多细微的差别。<b>诺加德则将 Airchat 定义为对话网络而不是社交网络</b>。他解释说，他和纳瓦尔都非常热衷于交谈，结识新朋友，谈论有趣的事情，这在消费互联网上几乎是不可能的。因此，他们着手构建一个可以做到这一点的应用程序。</p><p>Twitter 和马斯克应该对 Airchat 的成立也起了很大的作用。有人在 Airchat 上向纳瓦尔提问：「这个 App 的终极目标是什么？」纳瓦尔以「爱与和平」为主题回答了一连串，其中最后一点就是「为了阻止世界领袖们在 Twitter 上互相叫嚣，然后将全世界拖入热核毁灭」。</p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic4.zhimg.com/v2-e79a1f2ec1f3c25ed0ac706ed02ec7ab_1440w.jpg" /><figcaption>纳瓦尔解释 Airchat 的终极目标是什么｜图片来源：Twitter@naval</figcaption></figure><p>和很多早期邀请制 App 一样，<b>目前 Airchat 的用户画像是精英化的，从硅谷的从业人员、投资人到科技公司创始人。OpenAI 的 CEO Sam Altman 就出现在了这个 App 上</b>，包括《华盛顿邮报》的科技记者泰勒·洛伦兹（Taylor Lorenz）、前共和党国会议员乔治·桑托斯（George Santos）等等。</p><p>随着大量用户的涌入，许多人已经开始在社交网络上讨论 Airchat，大部分是正面的，毕竟用「听的方式刷 Twitter」这种体验此前是没有过的。创作者经济组织 Creator Economy NYC 的创始人布雷特·达舍夫斯基（Brett Dashevsky）自称是狂热的 Twitter 用户，但是眼下他使用 Airchat 的平均时间已经超过了 Twitter。「<b>这个平台有一些更人性化和有趣的东西，这是 Threads 和 Twitter 所没有的</b>，」他告诉 Business Insider。</p><p>当然也不都是表扬，Wired 记者劳伦·古德（Lauren Goode）就对 Airchat 的内容审查制度表示了担忧。纳瓦尔相信语音的力量可以减少尖锐的言辞，这在某种程度上说得通，但是减少并不意味着没有，甚至语音可能让发表尖锐言辞的交流过程更加顺畅了。</p><p>近日，一个名为「战争」的 Airchat 频道就被创建了，超过 529 名用户加入了其中。他们谈论的话题包括以色列的无人机袭击、加沙战争、对「经济武器」的想法、对石油价格的预测……很多人都表达了激烈的言辞，分享了未经证实的新闻，并且声称自己「做过了一些研究」。</p><p>目前尚不清楚这个频道是官方还是用户自行创建的。不过按照 Airchat 最新的平台规则，用户无法自行创建频道，但可以请求管理员创建频道。</p><p>由于创始人的理念，Airchat 的审核规则可以说是宽松的，甚至带有一些社区自治的意味。<b>Airchat 将其称之为「自我审核政策」，也就是当某人冒犯到你时，Airchat 建议你将其静音或者屏蔽</b>。Airchat 会移除骚扰、冒充、有粗俗行为和发布非法内容的用户，但不会因为礼貌的分歧或政治原因而在平台上移除用户</p><p>Airchat 的转录功能也备受用户好评，部分原因可能来自于当下 AI 技术的进步。<b>但是纳瓦尔似乎对大模型游戏不感兴趣，他对 Wired 表示不会训练一个关于用户声音的大语言模型，也不会将 Airchat 的数据出售给 AI 公司</b>，尤其是考虑到 Airchat 用户规模还比较小，数据也没有分类。不过，Airchat 可能会使用人们的语音数据来训练一个模型，以改进其自身的音频和转录功能——这取决于用户是否同意加入这个计划。</p><p>在商业化方面，Airchat 似乎还没有明确的计划。在与 TechCrunch 的访谈中，纳瓦尔明确表示公司没有任何盈利方面的压力，并且没有提到任何关于会员付费、音频广告相关的内容。目前 Airchat 的大部分资金来自纳瓦尔自己的风投基金，以及 Accomplice Ventures 的创始合伙人杰夫·法格南（Jeff Fagnan）。他还透露，<b>Sam Altman也「有点盲目地投入了一张支票」</b>。</p><h2><b>02 我们还需要另一个社交平台吗？</b></h2><p>Airchat 很容易让人想起另外一个流行过的语音平台——Clubhouse。Clubhouse 的流行迎合了疫情时代人们渴望与人交流的心理，但是在开放之后，这款爆红过的 App 又迅速被人遗忘。</p><p class="ztext-empty-paragraph"><br /></p><figure><img class="origin_image zh-lightbox-thumb" src="https://pic1.zhimg.com/v2-83f89e69f3af7a4b1ae04eb6fd36d8bc_1440w.jpg" /><figcaption>相比 2021 年 2 月，Clubhouse 的下载量在 4 月下降了 90%｜图片来源：yahoo</figcaption></figure><p><b>Airchat 会走 Clubhouse 的老路吗</b>？</p><p>和早期 Clubhouse 一样，Airchat 也采用了邀请制的注册方式。这是一种冷启动的好方式，早期加入的精英在平台上贡献高质量的内容，他们的粉丝也会随之来到新的平台。在最火爆的时期，一个 Clubhouse 邀请码甚至在 eBey 上卖出了 100 美元的高价。</p><p>从目前的态势来看，Airchat 很有可能复制 Clubhouse 的早期火爆。</p><p>不过，名人效应是短暂的。Clubhouse 主打的主题聊天室本质上和百度贴吧类似，凝聚他们的小众圈层的独特文化，这也意味着对大众的排斥。在 Clubhouse 开放注册之后，随着大量用户涌入，这种小圈子的稀缺性就被大大稀释。这是需要 Airchat 警惕的。</p><p><b>相比 Clubhouse，以异步的形式呈现语音内容是 Airchat 的优势</b>。Clubhouse 只提供「语音直播」一种场景，这也就意味着用户必须在特定的时间进入直播间，才能够消费内容，大大限制了用户的消费场景。</p><p>最开始 Clubhouse 的确成功了，但它也因此失败了。</p><p>乔布斯曾经评价 Dropbox 只是一个功能，谈不上产品。单一的功能容易被竞争对手复刻，产品可以提供一整套的服务，并以此建立壁垒。</p><p><b>Clubhouse 铺天盖地的宣传触发了大公司的防御机制</b>，在它出现一年内，Discord、Facebook、Slack、Spotify、Twitter 都相继推出了自己的直播音频功能。相比 Clubhouse，他们有更多的钱，更快的迭代速度，以及更多的用户。</p><p><b>Clubhouse 的问题也是 Airchat 的问题，仅仅是用「语音发推」这个功能而言，竞争对手可以毫不费力地模仿</b>。在全球范围内，Meta 和腾讯是最大的两家社交网络公司，而他们恰好也是模仿竞争对手的高手。</p><p>如果 Airchat 继续保持邀请制的排他性，它可能会演变为一个服务于小众精英的封闭平台；</p><p>如果 Airchat 持续火爆的话，不难预见，大型科技公司将会迅速跟进，推出竞品或模仿其核心功能；</p><p>如果 Airchat 真的想要成为一个没有激烈言论的社交网络的话，这也许是在和人性本身抗争。</p><p>这取决于两位创始人真正的目标是什么。但无论如何，他们也要面对一个残酷的事实：任何一个火爆全网的话题都会在下一个月迅速被人遗忘，这一点是不会改变的。</p><p>*头图来源：Twitter@lucas_crespo</p><p>本文为极客公园原创文章，转载请联系极客君微信 geekparkGO</p><p></p>
]]></content:encoded>
<pubDate>Tue, 07 May 2024 04:12:19 GMT</pubDate>
</item>
</channel>
</rss>